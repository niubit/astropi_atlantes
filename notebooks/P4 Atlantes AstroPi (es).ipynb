{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLXxJpOXAHrg"
   },
   "source": [
    "# Phase 4 AstroPi team Atlantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hP0P5ee7APCy"
   },
   "source": [
    "## Introducción\n",
    "\n",
    "En esta fase 4 del proyecto, dispondremos de los datos generados en la fase 3 por nuestro programa ejecutado en la Raspberry a bordo de la ISS. El objetivo de nuestro proyecto es hacer música con los datos obtenidos, es decir proceder a su [sonificación](https://en.wikipedia.org/wiki/Sonification). Una vez obtenido el sonido haremos una película [stopmotion](https://es.wikipedia.org/wiki/Animaci%C3%B3n_en_volumen) con las fotos obtenidas por la cámara de la Raspberry a la que superpondremos la sonificación de los datos de forma sincronizada.\n",
    "\n",
    "El proyecto propuesto en fase 1 pretendía consultar una fuente de datos meteorológicos históricos para obtener las condiciones climáticas en tierra en el momento y los lugares por los que pasó la ISS durante la ejecución de nuestro programa. Buscaremos una fuente de datos de este tipo y analizaremos si nos ofrece datos adecuados para nuestro propósito.\n",
    "\n",
    "Para analizar los datos utilizaremos representaciones en gráficas de las distintas columnas de datos obtenidos. Así identificaremos los que pueden resultar más adecuados para su sonificación. Aprenderemos por tanto a dibujar varias de estas columnas en la misma gráfica para poder compararlas.\n",
    "\n",
    "Una vez decidida la información que vamos a sonificar, utilizaremos código Python para producir a partir de los datos un fichero de sonido como resultado de nuestro proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpLlcTO1HJHy"
   },
   "source": [
    "## Preparando el entorno\n",
    "\n",
    "Para que este cuaderno se ejecute correctamente hay que instalar unos paquetes en el sandbox de Google Colab. También instalaremos los datos recopilados en la ISS y algunos ficheros necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51198,
     "status": "ok",
     "timestamp": 1622564736265,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "XWv5YvzuCQpM",
    "outputId": "5ea9905d-6ba8-4a41-faea-b24d3f4d9ca1"
   },
   "outputs": [],
   "source": [
    "!apt-get install -y fluidsynth fluid-soundfont-gm timidity ffmpeg\n",
    "!pip install meteostat geopandas pretty-midi MIDIUtil matplotlib jupyter\n",
    "!wget https://niubit.net/media/uploads/images/atlantes/atlantes_files_for_colab.zip -O atlantes_files_for_colab.zip\n",
    "!unzip -o -q atlantes_files_for_colab.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Er3djAnwsQe9"
   },
   "source": [
    "La siguiente celda de código termina de preparar el entorno y define algunas variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1622564736269,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "1KjZn_6EBdSn",
    "outputId": "ff921803-daaf-48ac-d911-ec0f792bf433"
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "\n",
    "# Adjusting chart dimensions    \n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)                  # Size of charts in inches\n",
    "plt.rcParams[\"figure.dpi\"] = 90                           # Resolution of charts in DPIs\n",
    "\n",
    "# Defining some environment variables for data sources\n",
    "path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "path_atlantes = path + \"/atlantes\"\n",
    "\n",
    "RESULTS_FILE = \"atlantes.csv\"                             # ESA CSV file\n",
    "RESULTS_FILE2 = \"atlantes_stations.csv\"                   # New CSV file with meteostat stations data\n",
    "RESULTS_FILE3 = \"atlantes_means.csv\"                      # New CSV file with pictures data\n",
    "RESULTS_FILE4 = \"atlantes_stations_plus_hourly.csv\"       # New CSV file with hourly meteostat data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdR4Y2lZ7cJd"
   },
   "source": [
    "## Fuente de datos meteorológicos\n",
    "\n",
    "La mejor fuente encontrada ha resultado ser [Meteostat](https://meteostat.net/en). Es libre, ofrece datos históricos y además tiene una [librería Python](https://dev.meteostat.net/python/) para obtener los datos desde código. Empezaremos analizando el sitio web de Meteostat consultando por ejemplo los datos [históricos que se pueden consultar sobre Zaragoza](https://meteostat.net/en/place/ES-SIWO).\n",
    "\n",
    "Analizando el [código básico de ejemplo de la librería meteostat](https://dev.meteostat.net/python/#example), vemos que las coordenadas de latitud/longitud introducidas como parámetros en el código, se utilizan para localizar en primer lugar la estación meteorológica más cercana, de la que luego se obtendrán los datos históricos. Es decir, los datos no procederán casi nunca de la localización exacta de la ISS, sino de la estación más cercana. Esto tiene sentido, pero nos hace darnos cuenta de que tal vez tengamos un problema, ya que la mayor parte del tiempo la ISS vuela sobre el mar, donde es de esperar que existan pocas estaciones. Cuando lo hace sobre tierra cada 15 segundos que es el intervalo de las fotos y la toma de datos se recorren aproximadamente 100km, por lo que al menos en las zonas pobladas es de esperar que podremos alcanzar la precisión suficiente.\n",
    "\n",
    "Será lo primero que vamos a analizar es decir, hasta qué punto las posiciones de sobrevuelo de la ISS están cubiertas por Meteostat con suficiente precisión. Vamos a recorrer el fichero CSV de datos de nuestro programa (`atlantes.csv`) para localizar la estación meteorológica de Meteostat más cercana a cada punto para ver con qué frecuencia cambia o se repite la estación. Luego representaremos estas estaciones sobre un mapa terrestre y compararemos los puntos con los de las posiciones de la ISS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y73fM30DHCDc"
   },
   "source": [
    "## Aprendiendo a trabajar con datos\n",
    "\n",
    "Antes tenemos que aprender una serie de técnicas en Python para acceder y manejar los datos del fichero CSV.\n",
    "\n",
    "El siguiente bloque de código utiliza la librería Python [`pandas`](https://pandas.pydata.org/pandas-docs/stable/index.html) para leer el fichero CSV. Lo carga sobre una estructura de datos propia de esta librería que facilita mucho la manipulación de matrices de datos del estilo de una hoja de cálculo. Vamos a empezar imprimiendo en pantalla la estructura de datos directamente para ver qué tenemos entre manos. Como contendrá muchos datos vamos a ver sólo las dos primeras filas, cosa que conseguimos con la función `head()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1622564736274,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "jMIBs0E5BOWf",
    "outputId": "efa4e0c9-3a54-4fca-f1fb-09a6b255a1b2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "# Building file path\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE)\n",
    "\n",
    "# Loading CSV file on memory\n",
    "data = pandas.read_csv(file)\n",
    "cut_data = data.head(2)                 # We get only the first two rows\n",
    "\n",
    "print(cut_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dv3GJWYx_lrG"
   },
   "source": [
    "Cuando queramos una única columna de datos será tan sencillo como indicar el nombre de la columna (el primer valor de la columna en el fichero CSV que actúa a modo de cabecera) separado de la estructura de datos con un punto: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1622564736277,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "3Rv86QDoB_6E",
    "outputId": "46ab7137-8749-4fb0-c6ad-7de9c104c119"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE)\n",
    "\n",
    "data = pandas.read_csv(file)\n",
    "sub_data = data.latitude                # Data subset with 'latitude' column\n",
    "cut_data = sub_data.head(2)             # We get only the first two rows\n",
    "\n",
    "print(cut_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVeGX_gx_1jS"
   },
   "source": [
    "Cuando queramos un conjunto de columnas, es decir una especie de subconjunto de la hoja CSV, utilizaremos la propiedad [`loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1622564736279,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "3pKZLzHsCDOY",
    "outputId": "45a0a6d3-d54f-4fab-b443-a9cca08078ce"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE)\n",
    "\n",
    "data = pandas.read_csv(file)\n",
    "# Data subset with 4 specific columns\n",
    "sub_data = data.loc[:, [\"datetime\", \"picture_file\", \"latitude\", \"longitude\"]]\n",
    "cut_data = sub_data.head(2)             # We get only the first two rows\n",
    "\n",
    "print(cut_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_GjgnFxAHia"
   },
   "source": [
    "Por último vamos a ver cómo iterar la estructura de datos para procesar cada fila que devuelve. Para conseguirlo utilizaremos la función [`iterrows()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iterrows.html) que nos devuelve para cada fila un índice y un diccionario con los datos que contiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1622564736281,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "6T5Ykct9CGci",
    "outputId": "d8aadd01-662b-49e8-ee02-29305fd7aeb9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE)\n",
    "\n",
    "data = pandas.read_csv(file)\n",
    "# Data subset with 4 specific columns\n",
    "sub_data = data.loc[:, [\"datetime\", \"picture_file\", \"latitude\", \"longitude\"]]\n",
    "cut_data = sub_data.head(2)             # We get only the first two rows\n",
    "\n",
    "for index, row in cut_data.iterrows():\n",
    "    print(index)\n",
    "    print(row[\"datetime\"])\n",
    "    print(row[\"picture_file\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfiYPU4uA1O3"
   },
   "source": [
    "## Localización de las estaciones meteorológicas\n",
    "\n",
    "Ahora que ya sabemos leer los datos, vamos a empezar a procesarlos. Comenzaremos preprocesando algunos datos para poder representarlos gráficamente más adelante. Lo que vamos a hacer ahora es generar un nuevo fichero CSV con algunas columnas del fichero original que nos servirán de índice (para poder cruzar los datos entre varios ficheros) a las que añadiremos columnas nuevas con datos de las estaciones meteorológicas más próximas a la latitud/longitud en la que se encontraba la ISS en cada iteración.\n",
    "\n",
    "El siguiente bloque de código coge el fichero `atlantes.csv` y para cada fila realiza lo siguiente:\n",
    "\n",
    "1. Obtiene las columnas de la latitud/longitud.\n",
    "2. Consulta la estación meteorológica más cercana a esa posición.\n",
    "3. En un nuevo CSV registra los siguientes datos con la cabecera que se indica:\n",
    "    * `datetime`: fecha/hora procedente del fichero original\n",
    "    * `picture_file`: nombre de fichero de la foto procedente del fichero original\n",
    "    * `latitude`: latitud procedente del fichero original\n",
    "    * `longitude`: longitud procedente del fichero original\n",
    "    * `station_id`: ID de la estación meteorológica en la base de datos de meteostat\n",
    "    * `station`: nombre de la estación meteorológica\n",
    "    * `country`: pais de la estación meteorológica\n",
    "    * `st_lat`: latitud de la estación meteorológica\n",
    "    * `st_lon`: longitud de la estación meteorológica\n",
    "\n",
    "El resultado de todo esto será el nuevo fichero `atlantes_stations.csv` que generaremos en el mismo directorio donde estaba la fuente de datos `atlantes.csv`.\n",
    "\n",
    "Esta vez vamos a trabajar con la fuente de datos (el fichero CSV original) completa, por lo que la ejecución puede tardar bastante tiempo en completarse (unos 5 minutos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309059,
     "status": "ok",
     "timestamp": 1622565045310,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "yiLIAt38CJ5K",
    "outputId": "3f2134d2-002a-444f-a319-bc1e83ca8225"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas\n",
    "from meteostat import Stations\n",
    "\n",
    "file_in = os.path.join(path_atlantes, RESULTS_FILE)    # Ruta completa fichero CSV entrada\n",
    "file_out = os.path.join(path_atlantes, RESULTS_FILE2)  # Ruta completa fichero CSV salida\n",
    "# Objeto de la librería meteostat para consultar estaciones meteorológicas de la base de datos meteostat\n",
    "stations = Stations()\n",
    "\n",
    "file = open(file_out, 'w', newline='', encoding='utf-8')     # Abrimos fichero de salida en modo escritura (`w`)\n",
    "\n",
    "# Leemos las columnas que nos interesan del fichero original\n",
    "data = pandas.read_csv(file_in).loc[:, [\"datetime\", \"picture_file\", \"latitude\", \"longitude\"]]\n",
    "\n",
    "# Escribimos cabecera de las columnas del fichero de salida\n",
    "header = (\"datetime\", \"picture_file\", \"latitude\", \"longitude\", \"station_id\", \"station\", \"country\", \"st_lat\", \"st_lon\")\n",
    "csv.writer(file).writerow(header)\n",
    "\n",
    "# Iteramos los datos del fichero de entrada\n",
    "for index, row in data.iterrows():\n",
    "    # Buscamos la estación meteorológica más cercana al punto sobre el que se encontraba la ISS\n",
    "    station = stations.nearby(row[\"latitude\"], row[\"longitude\"]).fetch(1)\n",
    "    # Escribimos los datos en el fichero de salida\n",
    "    csv.writer(file).writerow((row[\"datetime\"], row[\"picture_file\"], row[\"latitude\"], row[\"longitude\"], station.index[0], station[\"name\"][0], station[\"country\"][0], station[\"latitude\"][0], station[\"longitude\"][0]))\n",
    "\n",
    "# Cerramos el fichero de salida\n",
    "file.close()\n",
    "\n",
    "# Avisamos de la finalización del proceso\n",
    "print(\"Fichero '%s' generado.\" % (file_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-HG-iMXEOrD"
   },
   "source": [
    "Así pues ahora, tenemos en un mismo fichero los datos de la posición de la ISS en cada iteración de nuestro programa de captura de datos, junto a la posición de la estación meteorológica más próxima.\n",
    "\n",
    "Aquí empieza lo interesante. Vamos a dibujar sobre un plano dichas posiciones (gracias a [este artículo](https://coderzcolumn.com/tutorials/data-science/plotting-static-maps-with-geopandas-working-with-geospatial-data) por la idea) para así comprobar si los datos que obtendremos de las estaciones tendrán la suficiente precisión.\n",
    "\n",
    "El siguiente bloque de código dibuja y georreferencia sobre un plano terrestre las posiciones de la ISS en azul y las de las estaciones meteorológicas más próximas en rojo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "executionInfo": {
     "elapsed": 1235,
     "status": "ok",
     "timestamp": 1622565046536,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "fd1f5rsB_mGb",
    "outputId": "ba4f4cff-51b6-49fb-cee5-d75d3b430c03"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE2)  # Ruta completa fichero CSV entrada\n",
    "\n",
    "data = pandas.read_csv(file)                  # Leemos el fichero completo\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "with plt.style.context((\"seaborn\", \"ggplot\")):\n",
    "    world.plot(figsize=(18,10), color=\"white\", edgecolor=\"grey\")\n",
    "    # Dibujamos en rojo los puntos de las estaciones meteorológicas más próximas a la ISS\n",
    "    plt.scatter(data.st_lon, data.st_lat, zorder=1, alpha= 0.2, c='red', s=30)\n",
    "    # Dibujamos en azul los puntos donde se encontraba la ISS en cada iteración\n",
    "    plt.scatter(data.longitude, data.latitude, zorder=1, alpha= 0.2, c='blue', s=30)\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.title(\"Meteostat stations closer to ISS path\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKQorgv3Fg7D"
   },
   "source": [
    "Podemos ver cómo cuando la ISS sobrevuela zonas de tierra (sobre todo en América), hay numerosas estaciones meteorológicas de manera que las dos curvas casi se ajustan perfectamente. Sin embargo en la mayoría de las zonas, sobretodo cuando sobrevuela el mar, las estaciones dan saltos muy grandes. Los puntos se han representado con cierto nivel de transparencia, de manera que el nivel de opacidad del punto indica el número de veces que se repite una misma estación. Por eso las estaciones meteorológicas representadas sobre el mar tienen un rojo más intenso.\n",
    "\n",
    "Podemos recortar el gráfico para fijarnos con más detalle en algunas zonas, como el sobrevuelo de América, ajustando los extremos de los ejes X e Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "executionInfo": {
     "elapsed": 1581,
     "status": "ok",
     "timestamp": 1622565048101,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "hS5P5w4y_onE",
    "outputId": "ee70bf16-eb94-4626-ae0d-3bc08b61cdec"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE2)  # Ruta completa fichero CSV entrada\n",
    "\n",
    "data = pandas.read_csv(file, nrows=419).tail(113)          # Leemos los datos del sobrevuelo americano (307 -> 419)\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "with plt.style.context((\"seaborn\", \"ggplot\")):\n",
    "    world.plot(figsize=(18,10), color=\"white\", edgecolor=\"grey\")\n",
    "    # Dibujamos en rojo los puntos de las estaciones meteorológicas más próximas a la ISS\n",
    "    plt.scatter(data.st_lon, data.st_lat, zorder=1, alpha= 0.2, c='red', s=30)\n",
    "    # Dibujamos en azul los puntos donde se encontraba la ISS en cada iteración\n",
    "    plt.scatter(data.longitude, data.latitude, zorder=1, alpha= 0.2, c='blue', s=30)\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.title(\"Meteostat stations closer to ISS path\");\n",
    "    plt.gca().set_xlim(-135, -35)                          # Ajustamos los límites del eje X\n",
    "    plt.gca().set_ylim(-30, 55)                            # Ajustamos los límites del eje Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAwQ_AkFF_OX"
   },
   "source": [
    "Resulta curioso ver cómo en el norte de América prácticamente hay una estación meteorológica justo debajo de cada posición de la ISS. Esta situación empeora al adentrarnos en el sur de América.\n",
    "\n",
    "También ayuda a entender el problema la representación de los puntos de las estaciones únicamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1622565048104,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "lZtDZk9eABtZ",
    "outputId": "156af163-bd81-4cc8-8ca7-40ba53033cef"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE2)  # Ruta completa fichero CSV entrada\n",
    "\n",
    "data = pandas.read_csv(file)                  # Leemos el fichero completo\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "with plt.style.context((\"seaborn\", \"ggplot\")):\n",
    "    world.plot(figsize=(18,10), color=\"white\", edgecolor=\"grey\")\n",
    "    # Dibujamos en rojo los puntos de las estaciones meteorológicas más próximas a la ISS\n",
    "    plt.scatter(data.st_lon, data.st_lat, zorder=1, alpha= 0.2, c='red', s=30)\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.title(\"Meteostat stations closer to ISS path\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJ5k4npiGb-b"
   },
   "source": [
    "Lo siguiente que haremos es localizar algunos puntos interesantes de la serie de datos. Visualizando las fotos y apoyándonos en la representación de los puntos que hemos hecho sobre el plano terrestre, podemos destacar los siguientes puntos (los indicaremos con el nombre del archivo de la foto):\n",
    "\n",
    "|Foto|Hora|Latitud|Longitud|Zona|GMaps|Evento|\n",
    "|:---|:---|:------|:-------|:---|:----|:------|\n",
    "|atlantes_038.jpg|19:55:44|-15.930611|-24.8557447|Atlántico Sur|[Ver](https://goo.gl/maps/CHLZuX2VouyLZW1F9)|Puesta de sol en Tierra|\n",
    "|atlantes_059.jpg|20:00:59|-30.835167|-11.039583|Atlántico Sur|[Ver](https://goo.gl/maps/W1tcUhtfSUg75Pv27)|Puesta de sol en ISS|\n",
    "|atlantes_172.jpg|20:29:14|-22.955139|113.971111|Lyndon Australia Occidental 6701, Australia|[Ver](https://goo.gl/maps/k7pcNEWZQ8wMmfbG7)|Rozamos el noroeste de Australia (de noche)|\n",
    "|atlantes_186.jpg|20:32:44|-12.696889|122.401889|Oceano Índico|[Ver](https://goo.gl/maps/NE26MTBpryoxowxN8)|Salida de sol en ISS|\n",
    "|atlantes_208.jpg|20:38:14|3.935500|134.405194|Pacífico Norte|[Ver](https://goo.gl/maps/Z3auiDeyTtsQGLXY9)|Salida de sol en Tierra|\n",
    "|atlantes_307.jpg|21:03:00|50.315444|-127.637972|Mount Waddington B, Columbia Británica, Canadá|[Ver](https://goo.gl/maps/TT29TYdrg9sQjVRp6)|Entramos en Norteamérica por Vancouver|\n",
    "|atlantes_354.jpg|21:14:45|25.587417|-80.278167|Bahía Vizcaína, Florida, EE. UU.|[Ver](https://goo.gl/maps/vTiZMuaKD4oBCAVZA)|Salimos de Norteamérica por Florida|\n",
    "|atlantes_361.jpg|21:16:30|20.581278|-75.737639|Parque Nacional la Mensura, Cuba|[Ver](https://goo.gl/maps/TYtAw2YighVEzSyKA)|Atravesamos Cuba|\n",
    "|atlantes_375.jpg|21:20:00|10.210778|-67.528250|Francisco Linares Alcántara, Aragua, Venezuela|[Ver](https://goo.gl/maps/Jafv6Diq6jrubAxL8)|Entramos en Sudamérica por Venezuela|\n",
    "|atlantes_409.jpg|21:28:30|-15.460444|-48.835306|Vila Propício - Goiás, Brasil|[Ver](https://goo.gl/maps/XmUCCiBxFYbwRfz56)|Puesta de sol en Tierra|\n",
    "|atlantes_419.jpg|21:31:00|-22.755972|-42.721722|Pitangas, Tanguá - Estado de Río de Janeiro, Brasil|[Ver](https://goo.gl/maps/XCbTjLmB2pYCdT8z8)|Salimos de Sudamérica por Brasil (de noche)|\n",
    "|atlantes_431.jpg|21:34:00|-31.078889|-34.374528|Atlántico Sur|[Ver](https://goo.gl/maps/TaNCgeFUYze6ocJS9)|Puesta de sol en ISS|\n",
    "|atlantes_558.jpg|22:05:45|-12.424111|98.999056|Océano Índico|[Ver](https://goo.gl/maps/PbLcyFiCTmpfuxFv5)|Salida de sol en ISS|\n",
    "|atlantes_568.jpg|22:08:15|-4.892667|104.524250|Bonglai, Banjit, Way Kanan, Lampung, Indonesia|[Ver](https://goo.gl/maps/7FMihUnspsf9Hpgo6)|Atravesamos Indonesia (de noche)|\n",
    "|atlantes_579.jpg|22:11:00|3.454056|110.452167|Mar de la China Meridional|[Ver](https://goo.gl/maps/39qwLnvBm84TEzLx8)|Salida de sol en Tierra|\n",
    "|atlantes_598.jpg|22:15:45|17.696722|121.141833|Katablangan, Conner, Apayao, Filipinas|[Ver](https://goo.gl/maps/uD1Bp2Wso1iLWcXN9)|Atravesamos Filipinas|\n",
    "|atlantes_624.jpg|22:22:15|35.641417|139.452500|Renkōji, Tama, Tokyo, Japón|[Ver](https://goo.gl/maps/rq9baVAamvxd9vG28)|Atravesamos Japón (muy nublado)|\n",
    "|atlantes_701.jpg|22:41:30|41.288306|-124.100111|Redwoods National Park ASBS State Water Quality Protection Area, California, EE. UU.|[Ver](https://goo.gl/maps/gwPPCWRfwoWGFyZa7)|Entramos en Norteamérica por California|\n",
    "\n",
    "Vamos a volver a representar las posiciones de la ISS sobre el plano terrestre pero esta vez señalando con distintos colores el nivel de insolación en el momento de realizar la foto. Dibujaremos los puntos correspondientes a la fase diurna en naranja, los anocheceres y amaneceres en rojo y la fase nocturna en azul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "executionInfo": {
     "elapsed": 1319,
     "status": "ok",
     "timestamp": 1622565049395,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "qWGak7KqAGv6",
    "outputId": "d669fa13-f152-4452-bbcf-896497aaa6dd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE2)  # Ruta completa fichero CSV entrada\n",
    "\n",
    "#data = pandas.read_csv(file)                  # Leemos el fichero completo\n",
    "dataD1 = pandas.read_csv(file, nrows=38).tail(38)                  # Día 1\n",
    "dataA1 = pandas.read_csv(file, nrows=59).tail(21)                  # Anochecer 1\n",
    "dataN1 = pandas.read_csv(file, nrows=186).tail(127)                # Noche 1\n",
    "dataM1 = pandas.read_csv(file, nrows=208).tail(22)                 # Amanecer 1\n",
    "dataD2 = pandas.read_csv(file, nrows=409).tail(201)                # Día 2\n",
    "dataA2 = pandas.read_csv(file, nrows=431).tail(22)                 # Anochecer 2\n",
    "dataN2 = pandas.read_csv(file, nrows=558).tail(127)                # Noche 2\n",
    "dataM2 = pandas.read_csv(file, nrows=579).tail(21)                 # Amanecer 2\n",
    "dataD3 = pandas.read_csv(file, nrows=713).tail(134)                # Día 3\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "with plt.style.context((\"seaborn\", \"ggplot\")):\n",
    "    world.plot(figsize=(18,10), color=\"white\", edgecolor=\"grey\")\n",
    "    plt.scatter(dataD1.longitude, dataD1.latitude, zorder=1, alpha= 0.2, c='orange', s=30)\n",
    "    plt.scatter(dataA1.longitude, dataA1.latitude, zorder=1, alpha= 0.2, c='red', s=30)\n",
    "    plt.scatter(dataN1.longitude, dataN1.latitude, zorder=1, alpha= 0.2, c='blue', s=30)\n",
    "    plt.scatter(dataM1.longitude, dataM1.latitude, zorder=1, alpha= 0.2, c='red', s=30)\n",
    "    plt.scatter(dataD2.longitude, dataD2.latitude, zorder=1, alpha= 0.2, c='orange', s=30)\n",
    "    plt.scatter(dataA2.longitude, dataA2.latitude, zorder=1, alpha= 0.2, c='red', s=30)\n",
    "    plt.scatter(dataN2.longitude, dataN2.latitude, zorder=1, alpha= 0.2, c='blue', s=30)\n",
    "    plt.scatter(dataM2.longitude, dataM2.latitude, zorder=1, alpha= 0.2, c='red', s=30)\n",
    "    plt.scatter(dataD3.longitude, dataD3.latitude, zorder=1, alpha= 0.2, c='orange', s=30)\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.title(\"Insolation conditions: Orange=day; Red=dawn/sunset; Blue=night\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1diIZm0VjvQ"
   },
   "source": [
    "Con todo lo visto hasta ahora, se confirma que la mejor serie de datos es la que habíamos señalado antes y que corresponde al sobrevuelo sobre el continente americano, es decir entre las fotos `atlantes_307.jpg` y `atlantes_419.jpg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sq1ijLM0LgBU"
   },
   "source": [
    "## Tratamiento de datos sobre las fotografías\n",
    "\n",
    "Además de obtener datos de la mayoría de los sensores de SenseHAT, nuestro programa tomó una foto en cada iteración del bucle (cada 15 segundos). Estas fotos pueden considerarse también el resultado de la medición de un sensor (la cámara) y podemos extraer datos de las mismas. Un dato muy sencillo de obtener y de entender es el del promedio de todos los valores que tienen todos los píxeles de cada foto. Como sabemos, cada píxel tiene un valor entero de 0 a 255 para cada uno de los 3 canales de colores básicos (R: Rojo, G: Verde, B: Azul). También podemos promediar estos tres valores para cada píxel para obtener una especie de valor de luminosidad (es lo que se suele hacer para convertir las imágenes a blanco y negro). Así pues, en total vamos a obtener 4 valores promedio para cada foto:\n",
    "\n",
    "* Promedio de luminosidad de todos los píxeles de cada foto.\n",
    "* Promedio del valor R de todos los píxeles de cada foto.\n",
    "* Promedio del valor G de todos los píxeles de cada foto.\n",
    "* Promedio del valor B de todos los píxeles de cada foto.\n",
    "\n",
    "Para no tener que estar calculando cada vez estos promedios, dado que es un proceso pesado (cada foto contiene millones de píxeles), vamos a hacer un programa para preprocesar estos datos y registrarlos en un nuevo fichero CSV de forma parecida a como hicimos con las estaciones meteorológicas más próximas.\n",
    "\n",
    "El siguiente programa lee el fichero CSV que nos entregó la ESA con los datos originales registrados por la Raspberry y genera un nuevo fichero CSV con los cálculos realizados sobre las fotos de los cuatro promedios que hemos enumerado antes. El fichero original es `atlantes.csv` y el nuevo `atlantes_means.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25503,
     "status": "ok",
     "timestamp": 1622565074886,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "3559r-2zCGNK",
    "outputId": "d660c78d-9660-45c8-fa2f-124d46e0d8bb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas\n",
    "from PIL import Image, ImageStat\n",
    "\n",
    "file_in = os.path.join(path_atlantes, RESULTS_FILE)    # Ruta completa fichero CSV entrada\n",
    "file_out = os.path.join(path_atlantes, RESULTS_FILE3)  # Ruta completa fichero CSV salida\n",
    "\n",
    "file = open(file_out, 'w', newline='', encoding='utf-8')     # Abrimos fichero de salida en modo escritura (`w`)\n",
    "\n",
    "# Leemos las columnas que nos interesan del fichero original\n",
    "data = pandas.read_csv(file_in).loc[:, ['datetime', 'picture_file']]\n",
    "\n",
    "# Escribimos cabecera de las columnas del fichero de salida\n",
    "header = (\"datetime\", \"picture_file\", \"mean_global\", \"mean_r\", \"mean_g\", \"mean_b\")\n",
    "csv.writer(file).writerow(header)\n",
    "\n",
    "# Iteramos los datos del fichero de entrada\n",
    "for index, row in data.iterrows():\n",
    "    # Cargamos en memoria la foto\n",
    "    im = Image.open(os.path.join(path_atlantes, row[1]))\n",
    "    # Obtenemos sus estadísticas, entre las que se incluyen los valores medios de los canales R, G y B\n",
    "    stat = ImageStat.Stat(im)\n",
    "    # Calculamos la media global\n",
    "    mean = round(sum(stat.mean)/len(stat.mean), 2)\n",
    "    # Escribimos los datos en el fichero de salida\n",
    "    csv.writer(file).writerow((row[0], row[1], mean, round(stat.mean[0], 2), round(stat.mean[1], 2), round(stat.mean[2], 2)))\n",
    "\n",
    "# Cerramos el fichero de salida\n",
    "file.close()\n",
    "\n",
    "# Avisamos de la finalización del proceso\n",
    "print(\"Fichero '%s' generado.\" % (file_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6fI8fX_vg9o"
   },
   "source": [
    "## Generación de gráficas\n",
    "\n",
    "El fichero CSV generado en la fase 3 por nuestro programa ejecutado a bordo de la ISS contiene las siguientes columnas (y unidades):\n",
    "\n",
    "* datetime (AAAA-MM-DD HH:MM:SS.mmm)\n",
    "* picture_file (atlantes_NNN.jpg)\n",
    "* latitude (º)\n",
    "* longitude (º)\n",
    "* temp_cpu (ºC)\n",
    "* temp_h (ºC)\n",
    "* temp_p (ºC)\n",
    "* humidity (%)\n",
    "* pressure (mbar)\n",
    "* pitch (rad)\n",
    "* roll (rad)\n",
    "* yaw (rad)\n",
    "* mag_x (μT)\n",
    "* mag_y (μT)\n",
    "* mag_z (μT)\n",
    "* accel_x (g)\n",
    "* accel_y (g)\n",
    "* accel_z (g)\n",
    "* gyro_x (rad/s)\n",
    "* gyro_y (rad/s)\n",
    "* gyro_z (rad/s)\n",
    "\n",
    "A estas columnas podemos añadir los promedios de los píxeles de las fotos que hemos calculado antes, es decir:\n",
    "\n",
    "* Promedio global (0-255)\n",
    "* Promedio R (0-255)\n",
    "* Promedio G (0-255)\n",
    "* Promedio B (0-255)\n",
    "\n",
    "Con todos estos datos vamos a dibujar gráficas para visualmente decidir cuales de ellos podrán resultar más adecuados para ser sonificados. Durante las comparaciones pueden darse dos situaciones:\n",
    "\n",
    "1. Comparar datos con la misma unidad, como por ejemplo `temp_cpu`, `temp_h` y `temp_p`\n",
    "2. Comparar datos con distintas unidades, como por ejemplo `temp_cpu` y `mag_x`\n",
    "\n",
    "En el primer caso dibujaremos las clásicas gráficas con dos ejes de coordenadas, X y Y. En este caso podremos representar tantas columnas de datos como deseemos.\n",
    "\n",
    "En el segundo caso haremos gráficos con dos ejes verticales, uno a cada lado de la gráfica. En este último caso sólo podremos representar dos columnas de datos. Vamos a ver cómo hacer estos dos tipos de gráficas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ox28NryHb-g"
   },
   "source": [
    "### Gráficas tipo 1: Datos con misma unidad\n",
    "\n",
    "Por ejemplo vamos a dibujar en una misma gráfica los cuatro promedios calculados sobre las fotos al principio de este cuaderno. Los datos los tomaremos por tanto del fichero CSV `atlantes_means.csv`. La columna `datetime` hay que convertirla a objetos Python datetime para que la librería de gráficos interprete correctamente las fechas. Esto se hace indicando la posición de la columna en el parámetro `parse_dates` de la función `read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "executionInfo": {
     "elapsed": 1138,
     "status": "ok",
     "timestamp": 1622565076011,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "nkgBaZwLCVxX",
    "outputId": "9ead5de5-30eb-4733-d377-f1d8f7f590ce"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE3)    # Ruta completa fichero CSV\n",
    "\n",
    "# Leemos todo el fichero\n",
    "data = pandas.read_csv(file, parse_dates=[0])\n",
    "\n",
    "# Columnas en fichero: \"datetime\", \"picture_file\", \"mean_global\", \"mean_r\", \"mean_g\", \"mean_b\"\n",
    "data_x = data.datetime                        # Datos de la columna 'datetime'\n",
    "data_y1 = data.mean_global                    # Datos de la columna 'mean_global'\n",
    "data_y2 = data.mean_r                         # Datos de la columna 'mean_r'\n",
    "data_y3 = data.mean_g                         # Datos de la columna 'mean_g'\n",
    "data_y4 = data.mean_b                         # Datos de la columna 'mean_b'\n",
    "\n",
    "fig, ax = plt.subplots()                                      # Preparamos los objetos para dibujar con matplotlib\n",
    "ax.plot(data_x, data_y1, label=\"Mean global\", color=\"yellow\") # Representamos los datos de 'mean_global' frente a 'datetime'\n",
    "ax.plot(data_x, data_y2, label=\"Mean R\", color=\"red\")         # Representamos los datos de 'mean_r' frente a 'datetime'\n",
    "ax.plot(data_x, data_y3, label=\"Mean G\", color=\"green\")       # Representamos los datos de 'mean_g' frente a 'datetime'\n",
    "ax.plot(data_x, data_y4, label=\"Mean B\", color=\"blue\")        # Representamos los datos de 'mean_b' frente a 'datetime'\n",
    "\n",
    "plt.legend()                                  # Incluimos una leyenda en la gráfica\n",
    "plt.grid()                                    # Incluimos una rejilla en la gráfica\n",
    "plt.show()                                    # Mostramos la gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZI62oSUMvsfF"
   },
   "source": [
    "A la vista de esta gráfica ya vemos que no hay demasiada diferencia entre los distintos canales de color de las fotos. A pesar de ello intentaremos \"interpretar\" cada canal con un instrumento distinto, ya que seguramente resultará un sonido armónico y con esas pequeñas disonancias o imperfecciones que se producen en una interpretación hecha por humanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0a5KLYzHitq"
   },
   "source": [
    "### Gráficas tipo 2: Datos con distintas unidades\n",
    "\n",
    "Para ilustrar este caso vamos a representar por ejemplo las columnas de datos `temp_p` (eje izquierdo) y `pressure` (eje derecho) frente al tiempo (gracias a [este artículo](https://cmdlinetips.com/2019/10/how-to-make-a-plot-with-two-different-y-axis-in-python-with-matplotlib/) por el ejemplo). En este caso utilizaremos el fichero CSV generado por la Raspberry directamente, es decir el `atlantes.csv`. En el código indicamos todas las cabeceras de las columnas que podríamos utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1622565076015,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "w6BzgFrSCZ_n",
    "outputId": "25e10be3-6986-4484-b557-1f6c28ebf06f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE)    # Ruta completa fichero CSV\n",
    "\n",
    "# Leemos todo el fichero\n",
    "data = pandas.read_csv(file, parse_dates=[0])\n",
    "\n",
    "# Columnas en fichero:\n",
    "#     \"datetime\", \"picture_file\", \"latitude\", \"longitude\", \"temp_cpu\", \"temp_h\", \"temp_p\",\n",
    "#     \"humidity\", \"pressure\", \"pitch\", \"roll\", \"yaw\", \"mag_x\", \"mag_y\", \"mag_z\",\n",
    "#     \"accel_x\", \"accel_y\", \"accel_z\", \"gyro_x\", \"gyro_y\", \"gyro_z\"\n",
    "\n",
    "data_x = data.datetime                        # Datos de la columna 'datetime'\n",
    "data_y1 = data.temp_p                         # Datos de la columna 'temp_p'\n",
    "data_y2 = data.pressure                       # Datos de la columna 'pressure'\n",
    "\n",
    "fig, ax = plt.subplots()                      # Preparamos los objetos para dibujar con matplotlib\n",
    "ax.set_xlabel('Datetime')                     # Ponemos leyenda al eje X\n",
    "\n",
    "ax.plot(data_x, data_y1, color=\"red\")         # Representamos los datos de 'temp_p' frente a 'datetime' en rojo\n",
    "ax.set_ylabel('Temp. P', color=\"red\")         # Ponemos leyenda al eje Y\n",
    "\n",
    "ax2 = ax.twinx()                              # Generamos un nuevo eje vertical en la gráfica\n",
    "ax2.plot(data_x, data_y2, color=\"blue\")       # Representamos los datos de 'pressure' frente a 'datetime' en azul\n",
    "ax2.set_ylabel(\"Pressure\", color=\"blue\")      # Ponemos leyenda al segundo eje Y\n",
    "\n",
    "ax.grid(axis='x')                             # Incluimos una rejilla del eje X en la gráfica\n",
    "plt.show()                                    # Mostramos la gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyL5H65v0hyO"
   },
   "source": [
    "Si necesitamos comparar más de dos series distintas de datos, aún tenemos una opción, que es situar las series una encima de otra en distintos gráficos con el eje horizontal coincidente. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1622565076617,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "u9o-weZp0m7k",
    "outputId": "d8a18d26-c6db-4909-9364-e53a185279f3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE)    # Ruta completa fichero CSV\n",
    "\n",
    "# Leemos todo el fichero e indicamos la columna que actuará como índice común para todos los datos\n",
    "data = pandas.read_csv(file, parse_dates=[0], index_col='datetime')\n",
    "\n",
    "data[['temp_p', 'pressure']].plot(subplots=True, grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQWAtF1zvzyr"
   },
   "source": [
    "Aunque no estamos analizando los datos todavía, a la vista de la gráfica anterior no podemos dejar de destacar que se aprecia una evidente correlación entre la temperatura y presión del interior de la estación con el nivel de insolación, ya que los dos mínimos de ambas curvas, se corresponden bastante aproximadamente con los finales de los momentos en que la Tierra eclipsó al Sol en las casi dos órbitas completas de las que tenemos datos.\n",
    "\n",
    "Con estas técnicas de representación podremos hacer un análisis de los datos de cara a identificar las mejores series de datos para proceder a su sonificación.\n",
    "\n",
    "A continuación nos ocuparemos de las técnicas de sonificación propiamente dichas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsEX4MiZHr2a"
   },
   "source": [
    "## Empezando a sonificar\n",
    "\n",
    "Para sonificar series de datos, la mejor herramienta encontrada es la librería [sonify](https://github.com/erinspace/sonify). Aunque no vamos a utilizar la versión original sino una [modificada en Niubit](https://github.com/niubit/sonify) que permite más control sobre el escalado de los datos y guardar los ficheros MIDI generados. También modificamos el tempo para utilizar 60 beats por segundo que facilita el control de tiempos.\n",
    "\n",
    "Una demostración de la librería en acción es el cuaderno [Graphs_and_Sounds](https://github.com/erinspace/sonify/blob/master/examples/Graphs_and_Sounds.ipynb) que se encuentra dentro del directorio `examples` tanto del [repositorio original](https://github.com/erinspace/sonify) como de [nuestro fork](https://github.com/niubit/sonify). Nosotros vamos a hacer lo mismo que se ve en ese cuaderno pero utilizando nuestros datos como fuente.\n",
    "\n",
    "La librería `sonify` no se encuentra en [Pypi](https://pypi.org/) por lo que no puede instalarse con el comando `pip`. Hay que colocar su código fuente junto al cuaderno Jupyter o script Python que la utilizará. Si se ha ejecutado la primera celda de código de este cuaderno, ya tendremos la librería `sonify` instalada.\n",
    "\n",
    "La sonificación la haremos con la función `create_midi_from_data()` a la que hay que pasar como argumentos una lista de tuplas (x, y) en donde `x` es el tiempo en segundos e `y` el código MIDI de la nota a producir. En la siguiente tabla podemos ver la correspondencia entre los códigos MIDI y las notas reales:\n",
    "\n",
    "![MIDI table](https://niubit.net/media/uploads/images/atlantes/midinote2.jpeg)\n",
    "\n",
    "Como vemos las notas pueden tener un valor entero de 0 a 127. Habrá pues que asegurarse de que la serie de datos que pasamos a la función `create_midi_from_data()` contiene números entre 0 y 127 en la segunda posición de cada tupla, es decir lo que hemos llamado `y` antes. Para facilitar esta tarea existe en la librería `sonify` la función `scale_list_to_range(list_to_scale, new_min, new_max)` a la que le pasamos la lista de datos y los extremos mínimo y máximo en donde queremos que se \"reescale\" nuestra lista. Es decir, se asignará el mínimo de la lista `list_to_scale` a `new_min` y el máximo a `new_max`; el resto de valores intermedios de la lista se repartirán de forma proporcional entre los dos extremos. Vamos a verlo con un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1622565076623,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "HQh6ftHyCg5w",
    "outputId": "11ed620a-e5f4-4bea-9586-265a15bfbc30"
   },
   "outputs": [],
   "source": [
    "import sonify\n",
    "\n",
    "my_list = [4, 6, 7, 8]\n",
    "\n",
    "rescaled_list_14_18 = sonify.scale_list_to_range(my_list, 14, 18)\n",
    "rescaled_list_0_100 = sonify.scale_list_to_range(my_list, 0, 100)\n",
    "\n",
    "print(rescaled_list_14_18)\n",
    "print(rescaled_list_0_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luV-xXMpwbaX"
   },
   "source": [
    "Existe otra función parecida en nuestro fork de la librería `sonify` que nos permite un mayor control en el escalado de los datos. Se trata de la función `scale_list_to_range2(list_to_scale, new_min, new_max, old_min, old_max)`. Funciona igual que la comentada antes, pero en lugar de utilizar como base del escalado los valores extremos de la lista, nos permite indicarlos manualmente. Lo vemos con un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1622565076625,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "sCUwK8aoDO6L",
    "outputId": "d849ed89-5810-4d02-9f5c-cdff6de768dd"
   },
   "outputs": [],
   "source": [
    "import sonify\n",
    "\n",
    "my_list = [4, 6, 7, 8]\n",
    "\n",
    "rescaled_list_14_18 = sonify.scale_list_to_range2(my_list, 14, 18, 0, 10)\n",
    "rescaled_list_0_100 = sonify.scale_list_to_range2(my_list, 0, 100, 0, 10)\n",
    "\n",
    "print(rescaled_list_14_18)\n",
    "print(rescaled_list_0_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xd48ggR7wheI"
   },
   "source": [
    "### Sonificando una lista de un canal\n",
    "\n",
    "Antes de sonificar los datos reales vamos a hacer una prueba sencilla para conocer el uso de la librería `sonify` sonificando la lista anterior. El valor `x` de las tuplas que como sabemos indica el tiempo en segundos lo incrementaremos medio segundo en cada tupla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "executionInfo": {
     "elapsed": 2426,
     "status": "ok",
     "timestamp": 1622565100654,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "6LIcKaZCD-7i",
    "outputId": "e3941162-eb32-400d-f548-6f8fe639c9ef"
   },
   "outputs": [],
   "source": [
    "import sonify\n",
    "import IPython\n",
    "\n",
    "my_list = [4, 6, 7, 8]\n",
    "snd_f = \"my_list\"\n",
    "\n",
    "# Normalizamos los datos entre 20 y 100\n",
    "normalized_list = sonify.scale_list_to_range2(my_list, new_min=20, new_max=100, old_min=0, old_max=10)\n",
    "\n",
    "final_data = []\n",
    "x = 0\n",
    "for i in range(0, len(normalized_list)):\n",
    "    final_data.append((x, normalized_list[i]))\n",
    "    x += 0.5\n",
    "\n",
    "sonify.create_midi_from_data(final_data, file=snd_f+\".mid\")\n",
    "\n",
    "# Convertimos el fichero MIDI en WAV para reproducirlo en el cuaderno\n",
    "!fluidsynth /content/default.sf2 -F {snd_f}.wav -i -n -T wav {snd_f}.mid\n",
    "IPython.display.Audio(snd_f+\".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJqe-lKTwlKP"
   },
   "source": [
    "### Sonificando una lista de varios canales\n",
    "\n",
    "Con la librería `sonify` podemos crear sonido polifónico, es decir con varios instrumentos sonando simultáneamente. Para conseguirlo sólo tenemos que pasar a la función `create_midi_from_data()` de la librería `sonify` una lista de listas de tuplas en lugar de una simple lista de tuplas. El primer elemento de cada sublista de tuplas será el instrumento, que podremos elegir del diccionario `INSTRUMENTS` que hay dentro del fichero `constants.py` en la librería `sonify` (dentro del directorio que contiene su código).\n",
    "\n",
    "En el ejemplo anterior, la lista de tuplas que pasamos a `sonify` tenía esta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1622565105087,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "ld0nS1k-TWtY",
    "outputId": "b70ac3cd-17e4-4bf0-bc8b-33b96a8c567e"
   },
   "outputs": [],
   "source": [
    "my_list = [4, 6, 7, 8]\n",
    "\n",
    "# Normalizamos los datos entre 20 y 100\n",
    "normalized_list = sonify.scale_list_to_range2(my_list, new_min=20, new_max=100, old_min=0, old_max=10)\n",
    "\n",
    "final_data = []\n",
    "x = 0\n",
    "for i in range(0, len(normalized_list)):\n",
    "    final_data.append((x, normalized_list[i]))\n",
    "    x += 0.5\n",
    "\n",
    "print(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVj3GHfrwpKl"
   },
   "source": [
    "Ahora necesitamos una lista de listas (truco: la función [`zip()`](https://docs.python.org/es/3.8/library/functions.html#zip) de Python convierte dos listas en una lista de tuplas barajando los elementos de ambas listas; en realidad produce lo que se llama un iterador que podemos convertir en una lista mediante la función [`list()`](https://docs.python.org/es/3.8/library/functions.html#func-list)). Al principio de cada lista de tuplas añadiremos un elemento individual (no una tupla) con el nombre del instrumento que interpretará esa lista (truco: podemos añadir un elemento a una lista con el operador `+`, pero ambos elementos a \"sumar\" deben ser listas; para convertir un elemento aislado en una lista lo escribiremos entre corchetes; podemos ver el truco en acción en las últimas líneas del siguiente código):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 622,
     "status": "ok",
     "timestamp": 1622565108533,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "VWOTPb20TZrP",
    "outputId": "fd4908fd-88f7-4298-a495-fb00e37477fa"
   },
   "outputs": [],
   "source": [
    "list_y1 = [4, 6, 7, 8]\n",
    "list_y2 = [1, 3, 1, 3]\n",
    "list_y3 = [8, 7, 6, 4]\n",
    "\n",
    "# Normalizamos los datos entre 20 y 100\n",
    "normalized_y_list1 = sonify.scale_list_to_range2(list_y1, new_min=20, new_max=100, old_min=0, old_max=10)\n",
    "normalized_y_list2 = sonify.scale_list_to_range2(list_y2, new_min=20, new_max=100, old_min=0, old_max=10)\n",
    "normalized_y_list3 = sonify.scale_list_to_range2(list_y3, new_min=20, new_max=100, old_min=0, old_max=10)\n",
    "\n",
    "data_x = []\n",
    "x = 0\n",
    "for i in range(0, len(normalized_y_list1)):\n",
    "    data_x.append(x)\n",
    "    x += 0.5\n",
    "\n",
    "list_of_lists = []\n",
    "list_of_lists.append(['rock organ'] + list(zip(data_x, normalized_y_list1)))\n",
    "list_of_lists.append(['pizzicato strings'] + list(zip(data_x, normalized_y_list2)))\n",
    "list_of_lists.append(['oboe'] + list(zip(data_x, normalized_y_list3)))\n",
    "\n",
    "print(list_of_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzH9ed36wtjA"
   },
   "source": [
    "La sonificación de la lista de listas anterior es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "executionInfo": {
     "elapsed": 1692,
     "status": "ok",
     "timestamp": 1622565114142,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "u6_scPAqTczC",
    "outputId": "69f1017d-8eee-415a-96d5-b4f1081d7e31"
   },
   "outputs": [],
   "source": [
    "snd_f = \"list_of_lists\"\n",
    "sonify.create_midi_from_data(list_of_lists, track_type='multiple', file=snd_f+\".mid\")\n",
    "\n",
    "# Convertimos el fichero MIDI en WAV para reproducirlo en el cuaderno\n",
    "!fluidsynth /content/default.sf2 -F {snd_f}.wav -i -n -T wav {snd_f}.mid\n",
    "IPython.display.Audio(snd_f+\".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPBKwNp2wxsV"
   },
   "source": [
    "### Sonificando las medias de las fotografías\n",
    "\n",
    "El siguiente intento lo vamos a hacer ya con nuestros datos. Vamos a sonificar la serie completa de datos de la columna `mean_global` que generamos haciendo las medias de los valores de todos los píxeles de las fotografías en el apartado **Tratamiento de datos sobre las fotografías**. La lista de tiempos será una secuencia en la que cada elemento se incrementará en 0,1 para que se interpreten 10 notas por segundo. Hemos incrementado el ritmo porque la lista de datos es mucho más grande que las de los ejemplos anteriores, para que el clip de sonido resultante no sea muy largo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "output_embedded_package_id": "1fCTUmVpiu9nOC-46-V9yVY_joe9cN_FM"
    },
    "executionInfo": {
     "elapsed": 45848,
     "status": "ok",
     "timestamp": 1622565167232,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "vB32ck4tToBw",
    "outputId": "cdcadbbd-a424-487a-d208-ddb9457cc358"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import sonify\n",
    "import IPython\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE3)    # Ruta completa fichero CSV\n",
    "snd_f = \"pictures_mean_global\"\n",
    "\n",
    "# Leemos todo el fichero\n",
    "data = pandas.read_csv(file)\n",
    "\n",
    "# Columnas en fichero: \"datetime\", \"picture_file\", \"mean_global\", \"mean_r\", \"mean_g\", \"mean_b\"\n",
    "\n",
    "data_y1 = data.mean_global                    # Datos de la columna 'mean_global'\n",
    "\n",
    "# Normalizamos los datos entre 20 y 100\n",
    "data_y1_normalized = sonify.scale_list_to_range2(data_y1, new_min=20, new_max=100, old_min=0, old_max=255)\n",
    "\n",
    "final_data = []\n",
    "x = 0\n",
    "for i in range(0, len(data_y1_normalized)):\n",
    "    final_data.append((x, data_y1_normalized[i]))\n",
    "    x += 0.1\n",
    "\n",
    "sonify.create_midi_from_data(final_data, file=snd_f+\".mid\")\n",
    "\n",
    "# Convertimos el fichero MIDI en WAV para reproducirlo en el cuaderno\n",
    "!fluidsynth /content/default.sf2 -F {snd_f}.wav -i -n -T wav {snd_f}.mid\n",
    "IPython.display.Audio(snd_f+\".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIkf5bENw3WK"
   },
   "source": [
    "Esto ya empieza a coger ritmo.\n",
    "\n",
    "Lo siguiente será parecido pero con sonido polifónico, utilizando la técnica que hemos aprendido antes. Vamos a utilizar las cuatro columnas de medias de las fotografías que asociaremos a cuatro instrumentos distintos de la siguiente forma:\n",
    "\n",
    "* `mean_global` => steel drums\n",
    "* `mean_r` => rock organ\n",
    "* `mean_g` => pizzicato strings\n",
    "* `mean_b` => oboe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "output_embedded_package_id": "1bpMQ2vHfcHohu3LjZDnUdUtPeBUZmJD-"
    },
    "executionInfo": {
     "elapsed": 49120,
     "status": "ok",
     "timestamp": 1622565221131,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "FJet1U3bT6Vn",
    "outputId": "71beb477-26b4-496c-dd14-152584883276"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import sonify\n",
    "import IPython\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE3)    # Ruta completa fichero CSV\n",
    "snd_f = \"pictures_means\"\n",
    "\n",
    "# Leemos todo el fichero\n",
    "data = pandas.read_csv(file)\n",
    "\n",
    "# Columnas en fichero: \"datetime\", \"picture_file\", \"mean_global\", \"mean_r\", \"mean_g\", \"mean_b\"\n",
    "\n",
    "data_y1 = data.mean_global                    # Datos de la columna 'mean_global'\n",
    "data_y1_normalized = sonify.scale_list_to_range2(data_y1, new_min=20, new_max=100, old_min=0, old_max=255)\n",
    "data_y2 = data.mean_r                         # Datos de la columna 'mean_r'\n",
    "data_y2_normalized = sonify.scale_list_to_range2(data_y2, new_min=20, new_max=100, old_min=0, old_max=255)\n",
    "data_y3 = data.mean_g                         # Datos de la columna 'mean_g'\n",
    "data_y3_normalized = sonify.scale_list_to_range2(data_y3, new_min=20, new_max=100, old_min=0, old_max=255)\n",
    "data_y4 = data.mean_b                         # Datos de la columna 'mean_b'\n",
    "data_y4_normalized = sonify.scale_list_to_range2(data_y4, new_min=20, new_max=100, old_min=0, old_max=255)\n",
    "\n",
    "data_x = []\n",
    "x = 0\n",
    "for i in range(0, len(data_y1_normalized)):\n",
    "    data_x.append(x)\n",
    "    x += 0.1\n",
    "\n",
    "multitrack_data = []\n",
    "multitrack_data.append(list(zip(data_x, data_y1_normalized)))\n",
    "multitrack_data.append(list(zip(data_x, data_y2_normalized)))\n",
    "multitrack_data.append(list(zip(data_x, data_y3_normalized)))\n",
    "multitrack_data.append(list(zip(data_x, data_y4_normalized)))\n",
    "\n",
    "# Let's add some instruments to each track!\n",
    "instruments_to_add = ['steel drums', 'rock organ', 'pizzicato strings', 'oboe']\n",
    "\n",
    "multitrack_data_with_instruments = []\n",
    "for index, track in enumerate(multitrack_data):\n",
    "    multitrack_data_with_instruments.append([instruments_to_add[index]] + track)\n",
    "\n",
    "sonify.create_midi_from_data(multitrack_data_with_instruments, track_type='multiple', file=snd_f+\".mid\")\n",
    "\n",
    "# Convertimos el fichero MIDI en WAV para reproducirlo en el cuaderno\n",
    "!fluidsynth /content/default.sf2 -F {snd_f}.wav -i -n -T wav {snd_f}.mid\n",
    "IPython.display.Audio(snd_f+\".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6I3oQb8H76c"
   },
   "source": [
    "Lo siguiente será atacar finalmente la idea de sonificar las condiciones climáticas en tierra en los puntos por los que sobrevoló la estación como era nuestro objetivo inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQkYYvR0w9ef"
   },
   "source": [
    "## Selección de datos\n",
    "\n",
    "Como vimos en el apartado **Localización de las estaciones meteorológicas**, sólo cuando la ISS sobrevuela continentes muy poblados podemos contar con que el seguimiento de las estaciones meteorológicas en tierra será lo suficientemente detallado como para producir una serie de datos con buena resolución para que nuestro proyecto tenga posibilidades de éxito.\n",
    "\n",
    "Por este motivo, al final de ese apartado llegamos a la conclusión de que la serie de datos que vamos a utilizar es la que cubre el primer sobrevuelo sobre el continente americano:\n",
    "\n",
    "![Fly over america](https://niubit.net/media/uploads/images/atlantes/fly_over_america.png)\n",
    "\n",
    "Visualizando y analizando el contenido del fichero `atlantes_stations.csv` encontramos que esos dos puntos corresponden a las filas de las fotos siguientes (vamos a utilizar las fotos como índice dentro de los ficheros CSV):\n",
    "\n",
    "* Comienzo: `atlantes_307.jpg`\n",
    "* Fin: `atlantes_419.jpg`\n",
    "\n",
    "Vamos pues a interrogar a la librería `meteostat` para que nos ofrezca los datos de algunos parámetros climáticos en esas localizaciones en los instantes de tiempo en que la ISS las sobrevoló. Vamos a empezar con el valor de la temperatura. Como otras veces lo primero que haremos será preprocesar la información, ya que como vimos en las primeras pruebas con la librería `meteostat`, las consultas son lentas por lo que nos conviene registrar la información que obtengamos de ella para no tener que repetir las peticiones. Vamos a ampliar el fichero `atlantes_stations.csv` con una serie de nuevas columnas donde almacenaremos todos los datos que `meteostat` nos ofrece. En concreto nos permite obtener los siguientes parámetros climáticos:\n",
    "\n",
    "* `temp`: Temperatura del aire en °C\n",
    "* `dwpt`: Temperatura de rocío en °C\n",
    "* `rhum`: Humedad relativa en %\n",
    "* `prcp`: Precipitaciones en mm/hora\n",
    "* `snow`: Precipitaciones de nieve en mm\n",
    "* `wdir`: Dirección promedio del viento en grados (º)\n",
    "* `wspd`: Velocidad promedio del viento en km/h\n",
    "* `wpgt`: Velocidad máxima rachas de viento en km/h\n",
    "* `pres`: Presión media normalizada a nivel del mar en hPa\n",
    "* `tsun`: Minutos de insolación de la última hora en minutos\n",
    "* `coco`: [Código de condiciones climáticas](https://dev.meteostat.net/docs/formats.html#weather-condition-codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5661,
     "status": "ok",
     "timestamp": 1622565237865,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "9tpzKHXpUL7H",
    "outputId": "85947cb1-76c9-439a-a262-99ee71dec60a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas\n",
    "import datetime\n",
    "from meteostat import Hourly\n",
    "\n",
    "file_in = os.path.join(path_atlantes, RESULTS_FILE2)         # Ruta completa fichero CSV entrada\n",
    "file_out = os.path.join(path_atlantes, RESULTS_FILE4)        # Ruta completa fichero CSV salida\n",
    "\n",
    "data = pandas.read_csv(file_in, parse_dates=[0])             # Leemos el fichero\n",
    "\n",
    "file = open(file_out, 'w', newline='', encoding='utf-8')     # Abrimos fichero de salida en modo escritura (`w`)\n",
    "\n",
    "# Escribimos cabecera de las columnas del fichero de salida\n",
    "header = (\"datetime\", \"picture_file\", \"latitude\", \"longitude\", \"station_id\", \"station\", \"country\", \"st_lat\", \"st_lon\", \"temp\", \"dwpt\", \"rhum\", \"prcp\", \"snow\", \"wdir\", \"wspd\", \"wpgt\", \"pres\", \"tsun\", \"coco\")\n",
    "csv.writer(file).writerow(header)\n",
    "\n",
    "# Iteramos los datos del fichero de entrada\n",
    "for index, row in data.iterrows():\n",
    "    # Solicitamos la temperatura medida en la estación a la hora en la que la ISS sobrevoló\n",
    "    start_date = row[\"datetime\"]\n",
    "    end_date = row[\"datetime\"] + datetime.timedelta(hours=1)\n",
    "    station_data = Hourly(row[\"station_id\"], start_date, end_date).fetch()\n",
    "    \n",
    "    temp = station_data.temp[0] if len(station_data.temp) > 0 and not math.isnan(station_data.temp[0]) else \"\"\n",
    "    dwpt = station_data.dwpt[0] if len(station_data.dwpt) > 0 and not math.isnan(station_data.dwpt[0]) else \"\"\n",
    "    rhum = station_data.rhum[0] if len(station_data.rhum) > 0 and not math.isnan(station_data.rhum[0]) else \"\"\n",
    "    prcp = station_data.prcp[0] if len(station_data.prcp) > 0 and not math.isnan(station_data.prcp[0]) else \"\"\n",
    "    snow = station_data.snow[0] if len(station_data.snow) > 0 and not math.isnan(station_data.snow[0]) else \"\"\n",
    "    wdir = station_data.wdir[0] if len(station_data.wdir) > 0 and not math.isnan(station_data.wdir[0]) else \"\"\n",
    "    wspd = station_data.wspd[0] if len(station_data.wspd) > 0 and not math.isnan(station_data.wspd[0]) else \"\"\n",
    "    wpgt = station_data.wpgt[0] if len(station_data.wpgt) > 0 and not math.isnan(station_data.wpgt[0]) else \"\"\n",
    "    pres = station_data.pres[0] if len(station_data.pres) > 0 and not math.isnan(station_data.pres[0]) else \"\"\n",
    "    tsun = station_data.tsun[0] if len(station_data.tsun) > 0 and not math.isnan(station_data.tsun[0]) else \"\"\n",
    "    coco = station_data.coco[0] if len(station_data.coco) > 0 and not math.isnan(station_data.coco[0]) else \"\"\n",
    "    \n",
    "    # Escribimos los datos en el fichero de salida\n",
    "    csv.writer(file).writerow((row[\"datetime\"], row[\"picture_file\"], row[\"latitude\"], row[\"longitude\"], row[\"station_id\"], row[\"station\"], row[\"country\"], row[\"st_lat\"], row[\"st_lon\"], temp, dwpt, rhum, prcp, snow, wdir, wspd, wpgt, pres, tsun, coco))\n",
    "\n",
    "# Cerramos el fichero de salida\n",
    "file.close()\n",
    "\n",
    "# Avisamos de la finalización del proceso\n",
    "print(\"Fichero '%s' generado.\" % (file_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNGVk1mjxjoR"
   },
   "source": [
    "Observando el fichero CSV resultante vemos que `meteostat` nos suministra información para la mayoría de las localizaciones que hemos seleccionado, lo que es un buen comienzo.\n",
    "\n",
    "| datetime                   | picture_file     | temp | dwpt  | rhum  | prcp | snow | wdir  | wspd | wpgt | pres   | tsun | coco |\n",
    "|----------------------------|------------------|------|-------|-------|------|------|-------|------|------|--------|------|------|\n",
    "| 2021-04-16 21:03:00.005538 | atlantes_307.jpg | 10.2 | 7.4   | 83.0  | 0.0  |      | 270.0 | 5.4  |      | 1024.9 |      |      |\n",
    "| 2021-04-16 21:03:15.005907 | atlantes_308.jpg | 25.1 | 4.8   | 27.0  | 0.0  |      | 25.0  | 1.8  |      | 1023.1 |      |      |\n",
    "| 2021-04-16 21:03:30.006037 | atlantes_309.jpg | 18.0 | 4.2   | 40.0  | 0.0  |      | 60.0  | 7.6  |      | 1023.8 |      | 1.0  |\n",
    "| 2021-04-16 21:03:45.006218 | atlantes_310.jpg | 13.8 | 8.2   | 69.0  |      |      | 110.0 | 13.0 |      | 1023.5 |      |      |\n",
    "| 2021-04-16 21:04:00.006389 | atlantes_311.jpg | 23.0 | 2.5   | 26.0  | 0.0  |      | 170.0 | 7.6  |      | 1022.2 |      |      |\n",
    "| 2021-04-16 21:04:15.006411 | atlantes_312.jpg | 23.0 | -10.3 | 10.0  | 0.0  |      | 220.0 | 5.4  |      | 1023.9 |      |      |\n",
    "| 2021-04-16 21:04:30.006446 | atlantes_313.jpg | 23.0 | -3.4  | 17.0  | 0.0  |      | 230.0 | 11.0 |      | 1023.0 |      |      |\n",
    "| 2021-04-16 21:04:45.006630 | atlantes_314.jpg | 21.0 | -5.0  | 17.0  | 0.0  |      | 50.0  | 19.0 |      | 1024.0 |      |      |\n",
    "| 2021-04-16 21:05:00.006805 | atlantes_315.jpg | 19.0 | -5.9  | 18.0  | 0.0  |      | 360.0 | 19.0 |      | 1024.0 |      |      |\n",
    "| 2021-04-16 21:05:15.006873 | atlantes_316.jpg | 10.0 | -10.2 | 23.0  | 0.0  |      | 64.0  | 7.9  |      | 1025.0 |      |      |\n",
    "| 2021-04-16 21:05:30.007029 | atlantes_317.jpg | 15.6 | -5.5  | 23.0  | 0.0  |      | 130.0 | 16.6 |      | 1025.3 |      |      |\n",
    "| 2021-04-16 21:05:45.007137 | atlantes_318.jpg | 15.6 | -5.5  | 23.0  | 0.0  |      | 130.0 | 16.6 |      | 1025.3 |      |      |\n",
    "| 2021-04-16 21:06:00.007293 | atlantes_319.jpg | 13.3 | -8.0  | 22.0  | 0.0  |      | 350.0 | 27.7 |      | 1027.6 |      |      |\n",
    "| 2021-04-16 21:06:15.007372 | atlantes_320.jpg | 9.0  | -8.1  | 29.0  | 0.0  |      | 90.0  | 15.0 |      | 1025.0 |      |      |\n",
    "| 2021-04-16 21:06:30.007390 | atlantes_321.jpg | 9.0  | -8.1  | 29.0  | 0.0  |      | 90.0  | 15.0 |      | 1025.0 |      |      |\n",
    "| 2021-04-16 21:06:45.007528 | atlantes_322.jpg | 7.0  | -6.0  | 39.0  | 0.0  |      | 30.0  | 37.0 |      | 1025.0 |      |      |\n",
    "| 2021-04-16 21:07:00.007552 | atlantes_323.jpg | 2.8  | 0.0   | 82.0  | 0.3  |      | 320.0 | 29.5 |      | 1028.4 |      |      |\n",
    "| 2021-04-16 21:07:15.007685 | atlantes_324.jpg | 3.3  | -1.1  | 73.0  | 0.3  |      | 350.0 | 16.6 |      | 1025.7 |      |      |\n",
    "| 2021-04-16 21:07:30.007788 | atlantes_325.jpg | 4.0  | -1.0  | 70.0  | 0.0  |      | 330.0 | 26.0 |      | 1023.0 |      |      |\n",
    "| 2021-04-16 21:07:45.007964 | atlantes_326.jpg | 2.0  | -0.8  | 82.0  | 0.0  |      | 300.0 | 13.0 |      | 1023.0 |      |      |\n",
    "| 2021-04-16 21:08:00.008043 | atlantes_327.jpg | 2.0  | -0.8  | 82.0  | 0.0  |      | 300.0 | 13.0 |      | 1023.0 |      |      |\n",
    "| 2021-04-16 21:08:15.008081 | atlantes_328.jpg |      |       |       |      |      |       |      |      |        |      |      |\n",
    "| 2021-04-16 21:08:30.008379 | atlantes_329.jpg | 5.0  | 1.7   | 79.0  | 0.5  |      | 330.0 | 29.5 |      | 1021.2 |      |      |\n",
    "| 2021-04-16 21:08:45.008490 | atlantes_330.jpg |      |       |       |      |      |       |      |      |        |      |      |\n",
    "| 2021-04-16 21:09:00.008632 | atlantes_331.jpg | 4.0  | 2.7   | 91.0  | 0.5  |      | 340.0 | 20.0 |      | 1019.0 |      |      |\n",
    "| 2021-04-16 21:09:15.008670 | atlantes_332.jpg | 5.0  | 2.9   | 86.0  | 0.0  |      | 340.0 | 16.6 |      | 1018.2 |      |      |\n",
    "| 2021-04-16 21:09:30.008734 | atlantes_333.jpg | 7.0  | 4.8   | 86.0  | 0.3  |      | 20.0  | 7.0  |      | 1017.0 |      |      |\n",
    "| 2021-04-16 21:09:45.008740 | atlantes_334.jpg | 7.0  | 5.5   | 90.0  | 0.6  |      | 10.0  | 13.0 |      | 1016.0 |      |      |\n",
    "| 2021-04-16 21:10:00.008916 | atlantes_335.jpg | 7.0  | 6.3   | 95.0  | 0.4  |      | 10.0  | 19.0 |      | 1016.0 |      |      |\n",
    "| 2021-04-16 21:10:15.008948 | atlantes_336.jpg | 10.0 | 8.9   | 93.0  | 0.8  |      | 50.0  | 6.0  |      | 1014.0 |      |      |\n",
    "| 2021-04-16 21:10:30.009012 | atlantes_337.jpg | 10.0 | 10.0  | 100.0 | 0.5  |      | 60.0  | 6.0  |      | 1014.0 |      | 5.0  |\n",
    "| 2021-04-16 21:10:45.009113 | atlantes_338.jpg | 11.0 | 9.3   | 89.0  | 0.1  |      | 340.0 | 6.0  |      | 1014.0 |      |      |\n",
    "| 2021-04-16 21:11:00.009115 | atlantes_339.jpg | 13.0 | 9.1   | 77.0  | 0.0  |      | 95.0  | 8.3  |      | 1013.0 |      |      |\n",
    "| 2021-04-16 21:11:15.009173 | atlantes_340.jpg | 15.0 | 4.9   | 51.0  | 0.0  |      | 60.0  | 6.0  |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:11:30.009298 | atlantes_341.jpg | 15.0 | 7.1   | 59.0  | 0.0  |      | 50.0  | 6.0  |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:11:45.009406 | atlantes_342.jpg | 16.0 | 7.0   | 55.0  | 0.0  |      | 100.0 | 6.0  |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:12:00.009458 | atlantes_343.jpg | 17.0 | 8.2   | 56.0  | 0.0  |      | 346.0 | 3.2  |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:12:15.010704 | atlantes_344.jpg | 19.4 | 7.8   | 47.0  | 0.0  |      | 338.0 | 2.2  |      | 1010.5 |      |      |\n",
    "| 2021-04-16 21:12:30.010722 | atlantes_345.jpg | 19.0 | 8.3   | 50.0  | 0.0  |      | 350.0 | 7.0  |      | 1011.0 |      |      |\n",
    "| 2021-04-16 21:12:45.010722 | atlantes_346.jpg | 19.0 | 12.3  | 65.0  | 0.0  |      | 61.0  | 6.5  |      | 1011.0 |      |      |\n",
    "| 2021-04-16 21:13:00.010827 | atlantes_347.jpg |      |       |       |      |      |       |      |      |        |      |      |\n",
    "| 2021-04-16 21:13:15.011000 | atlantes_348.jpg | 18.3 | 18.3  | 100.0 | 1.3  |      | 80.0  | 13.0 |      | 1009.3 |      |      |\n",
    "| 2021-04-16 21:13:30.011110 | atlantes_349.jpg | 18.0 | 17.7  | 98.0  | 3.0  |      | 110.0 | 5.4  |      | 1011.0 |      |      |\n",
    "| 2021-04-16 21:13:45.011155 | atlantes_350.jpg | 24.0 | 20.9  | 83.0  | 0.0  |      | 240.0 | 13.0 |      | 1011.0 |      |      |\n",
    "| 2021-04-16 21:14:00.011237 | atlantes_351.jpg | 25.8 | 19.4  | 68.0  | 0.0  |      | 244.0 | 17.3 |      | 1010.5 |      |      |\n",
    "| 2021-04-16 21:14:15.012541 | atlantes_352.jpg | 26.0 | 18.9  | 65.0  | 0.0  |      | 240.0 | 17.0 |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:14:30.012680 | atlantes_353.jpg | 27.0 | 18.0  | 58.0  | 0.0  |      | 260.0 | 9.0  |      | 1011.0 |      |      |\n",
    "| 2021-04-16 21:14:45.012855 | atlantes_354.jpg | 27.0 | 17.8  | 57.0  | 0.0  |      | 180.0 | 13.0 |      | 1011.0 |      |      |\n",
    "| 2021-04-16 21:15:00.012925 | atlantes_355.jpg | 25.4 | 20.9  | 76.0  | 0.0  |      | 174.0 | 25.6 |      | 1010.6 |      |      |\n",
    "| 2021-04-16 21:15:15.013805 | atlantes_356.jpg | 25.4 | 20.9  | 76.0  | 0.0  |      | 174.0 | 25.6 |      | 1010.6 |      |      |\n",
    "| 2021-04-16 21:15:30.013831 | atlantes_357.jpg |      |       |       |      |      |       |      |      |        |      |      |\n",
    "| 2021-04-16 21:15:45.013968 | atlantes_358.jpg | 33.0 | 15.9  | 36.0  | 0.0  |      | 180.0 | 9.4  |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:16:00.013978 | atlantes_359.jpg | 33.0 | 15.9  | 36.0  | 0.0  |      | 180.0 | 9.4  |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:16:15.014030 | atlantes_360.jpg | 31.0 | 11.9  | 31.0  | 0.0  |      | 30.0  | 25.9 |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:16:30.014085 | atlantes_361.jpg | 31.0 | 11.9  | 31.0  | 0.0  |      | 30.0  | 25.9 |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:16:45.014247 | atlantes_362.jpg | 28.9 | 22.2  | 67.0  | 0.0  |      | 230.0 | 25.9 |      | 1012.3 |      |      |\n",
    "| 2021-04-16 21:17:00.014254 | atlantes_363.jpg | 28.9 | 22.2  | 67.0  | 0.0  |      | 230.0 | 25.9 |      | 1012.3 |      |      |\n",
    "| 2021-04-16 21:17:15.014262 | atlantes_364.jpg |      |       |       |      |      |       |      |      |        |      |      |\n",
    "| 2021-04-16 21:17:30.014365 | atlantes_365.jpg | 28.0 | 24.0  | 79.0  | 0.0  |      | 130.0 | 25.9 |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:17:45.014532 | atlantes_366.jpg | 28.0 | 24.0  | 79.0  | 0.0  |      | 130.0 | 25.9 |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:18:00.014589 | atlantes_367.jpg | 28.0 | 24.0  | 79.0  | 0.0  |      | 130.0 | 25.9 |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:18:15.014705 | atlantes_368.jpg | 28.0 | 24.0  | 79.0  | 0.0  |      | 130.0 | 25.9 |      | 1012.0 |      |      |\n",
    "| 2021-04-16 21:18:30.014789 | atlantes_369.jpg | 29.0 | 24.1  | 75.0  | 0.0  |      | 80.0  | 40.7 |      | 1009.0 |      | 1.0  |\n",
    "| 2021-04-16 21:18:45.014814 | atlantes_370.jpg | 29.0 | 24.1  | 75.0  | 0.0  |      | 80.0  | 40.7 |      | 1009.0 |      | 1.0  |\n",
    "| 2021-04-16 21:19:00.014908 | atlantes_371.jpg | 29.0 | 24.1  | 75.0  | 0.0  |      | 80.0  | 40.7 |      | 1009.0 |      | 1.0  |\n",
    "| 2021-04-16 21:19:15.015082 | atlantes_372.jpg | 28.0 | 22.9  | 74.0  | 0.0  |      | 80.0  | 24.1 |      | 1009.0 |      | 2.0  |\n",
    "| 2021-04-16 21:19:30.015442 | atlantes_373.jpg | 28.5 | 23.9  | 76.0  | 0.0  |      | 77.0  | 32.4 |      | 1009.5 |      | 3.0  |\n",
    "| 2021-04-16 21:19:45.015607 | atlantes_374.jpg | 26.0 | 22.1  | 79.0  | 0.0  |      | 95.0  | 4.0  |      | 1009.0 |      |      |\n",
    "| 2021-04-16 21:20:00.015665 | atlantes_375.jpg | 28.5 | 20.8  | 63.0  | 0.3  |      | 150.0 | 4.7  |      | 1009.8 |      |      |\n",
    "| 2021-04-16 21:20:15.015812 | atlantes_376.jpg |      |       |       |      |      |       |      |      |        |      |      |\n",
    "| 2021-04-16 21:20:30.015970 | atlantes_377.jpg | 30.2 | 22.1  | 62.0  | 0.0  |      | 121.0 | 4.7  |      | 1007.9 |      |      |\n",
    "| 2021-04-16 21:20:45.016121 | atlantes_378.jpg | 30.2 | 22.1  | 62.0  | 0.0  |      | 121.0 | 4.7  |      | 1007.9 |      |      |\n",
    "| 2021-04-16 21:21:00.016172 | atlantes_379.jpg | 30.6 | 21.1  | 57.0  | 0.0  |      | 87.0  | 12.2 |      | 1007.8 |      |      |\n",
    "| 2021-04-16 21:21:15.016223 | atlantes_380.jpg |      |       |       |      |      |       |      |      |        |      |      |\n",
    "| 2021-04-16 21:21:30.016978 | atlantes_381.jpg |      |       |       |      |      |       |      |      |        |      |      |\n",
    "| 2021-04-16 21:21:45.017138 | atlantes_382.jpg |      |       |       |      |      |       |      |      |        |      |      |\n",
    "| 2021-04-16 21:22:00.017232 | atlantes_383.jpg | 22.2 | 19.0  | 82.0  | 0.0  |      | 96.0  | 7.9  |      | 1011.0 |      |      |\n",
    "| 2021-04-16 21:22:15.017427 | atlantes_384.jpg | 22.2 | 19.0  | 82.0  | 0.0  |      | 96.0  | 7.9  |      | 1011.0 |      |      |\n",
    "| 2021-04-16 21:22:30.017556 | atlantes_385.jpg | 24.4 | 24.2  | 99.0  | 0.0  |      | 334.0 | 2.5  |      | 1008.3 |      |      |\n",
    "| 2021-04-16 21:22:45.017673 | atlantes_386.jpg | 24.4 | 24.2  | 99.0  | 0.0  |      | 334.0 | 2.5  |      | 1008.3 |      |      |\n",
    "| 2021-04-16 21:23:00.017681 | atlantes_387.jpg | 24.4 | 24.2  | 99.0  | 0.0  |      | 334.0 | 2.5  |      | 1008.3 |      |      |\n",
    "| 2021-04-16 21:23:15.017756 | atlantes_388.jpg | 24.4 | 24.2  | 99.0  | 0.0  |      | 334.0 | 2.5  |      | 1008.3 |      |      |\n",
    "| 2021-04-16 21:23:30.017828 | atlantes_389.jpg | 25.8 | 23.5  | 87.0  | 0.0  |      | 30.0  | 7.6  |      | 1007.5 |      |      |\n",
    "| 2021-04-16 21:23:45.017968 | atlantes_390.jpg | 25.8 | 23.5  | 87.0  | 0.0  |      | 30.0  | 7.6  |      | 1007.5 |      |      |\n",
    "| 2021-04-16 21:24:00.018016 | atlantes_391.jpg | 26.1 | 23.8  | 87.0  | 0.0  |      | 26.0  | 7.9  |      | 1007.4 |      |      |\n",
    "| 2021-04-16 21:24:15.018450 | atlantes_392.jpg | 27.6 | 24.2  | 82.0  | 0.0  |      | 80.0  | 5.8  |      | 1007.1 |      |      |\n",
    "| 2021-04-16 21:24:30.018555 | atlantes_393.jpg | 26.8 | 24.1  | 85.0  | 0.1  |      | 78.0  | 7.2  |      | 1007.5 |      |      |\n",
    "| 2021-04-16 21:24:45.018556 | atlantes_394.jpg | 26.8 | 24.1  | 85.0  | 0.1  |      | 78.0  | 7.2  |      | 1007.5 |      |      |\n",
    "| 2021-04-16 21:25:00.018616 | atlantes_395.jpg | 26.4 | 24.4  | 89.0  | 0.1  |      | 66.0  | 9.4  |      | 1008.0 |      |      |\n",
    "| 2021-04-16 21:25:15.018671 | atlantes_396.jpg | 26.4 | 24.4  | 89.0  | 0.1  |      | 66.0  | 9.4  |      | 1008.0 |      |      |\n",
    "| 2021-04-16 21:25:30.018742 | atlantes_397.jpg | 27.5 | 23.5  | 79.0  |      |      | 62.0  | 5.5  |      | 1009.0 |      | 3.0  |\n",
    "| 2021-04-16 21:25:45.018763 | atlantes_398.jpg | 23.3 | 22.3  | 94.0  | 0.5  |      | 86.0  | 11.2 |      | 1010.0 |      |      |\n",
    "| 2021-04-16 21:26:00.018784 | atlantes_399.jpg | 23.3 | 22.3  | 94.0  | 0.5  |      | 86.0  | 11.2 |      | 1010.0 |      |      |\n",
    "| 2021-04-16 21:26:15.018791 | atlantes_400.jpg | 23.3 | 22.3  | 94.0  | 0.5  |      | 86.0  | 11.2 |      | 1010.0 |      |      |\n",
    "| 2021-04-16 21:26:30.018937 | atlantes_401.jpg | 25.1 | 23.0  | 88.0  | 0.3  |      | 96.0  | 8.6  |      | 1009.5 |      |      |\n",
    "| 2021-04-16 21:26:45.018989 | atlantes_402.jpg | 25.1 | 23.0  | 88.0  | 0.3  |      | 96.0  | 8.6  |      | 1009.5 |      |      |\n",
    "| 2021-04-16 21:27:00.019069 | atlantes_403.jpg | 25.1 | 22.4  | 75.0  | 0.0  |      | 356.0 | 3.6  |      | 1009.6 |      |      |\n",
    "| 2021-04-16 21:27:15.019124 | atlantes_404.jpg | 25.1 | 22.4  | 75.0  | 0.0  |      | 356.0 | 3.6  |      | 1009.6 |      |      |\n",
    "| 2021-04-16 21:27:30.019154 | atlantes_405.jpg | 25.1 | 22.4  | 75.0  | 0.0  |      | 356.0 | 3.6  |      | 1009.6 |      |      |\n",
    "| 2021-04-16 21:27:45.019162 | atlantes_406.jpg | 25.1 | 22.4  | 75.0  | 0.0  |      | 356.0 | 3.6  |      | 1009.6 |      |      |\n",
    "| 2021-04-16 21:28:00.019205 | atlantes_407.jpg | 25.0 | 19.4  | 71.0  | 0.0  |      | 272.0 | 0.0  |      | 1009.7 |      |      |\n",
    "| 2021-04-16 21:28:15.020610 | atlantes_408.jpg | 25.0 | 19.4  | 71.0  | 0.0  |      | 272.0 | 0.0  |      | 1009.7 |      |      |\n",
    "| 2021-04-16 21:28:30.020769 | atlantes_409.jpg | 24.5 | 16.2  | 60.0  | 0.0  |      | 82.0  | 5.8  |      | 1010.2 |      |      |\n",
    "| 2021-04-16 21:28:45.020903 | atlantes_410.jpg |      |       |       |      |      |       |      |      |        |      |      |\n",
    "| 2021-04-16 21:29:00.021024 | atlantes_411.jpg | 20.0 | 13.9  | 68.0  | 0.0  |      | 81.0  | 6.5  |      | 1014.3 |      |      |\n",
    "| 2021-04-16 21:29:15.021039 | atlantes_412.jpg | 21.0 | 14.2  | 65.0  | 0.0  |      | 77.0  | 5.8  |      | 1012.8 |      |      |\n",
    "| 2021-04-16 21:29:30.021189 | atlantes_413.jpg | 21.1 | 12.8  | 59.0  | 0.0  |      | 95.0  | 7.4  |      | 1011.9 |      | 2.0  |\n",
    "| 2021-04-16 21:29:45.021263 | atlantes_414.jpg | 21.1 | 12.8  | 59.0  | 0.0  |      | 95.0  | 7.4  |      | 1011.9 |      | 2.0  |\n",
    "| 2021-04-16 21:30:00.021401 | atlantes_415.jpg | 22.0 | 12.0  | 53.0  | 0.0  |      | 77.0  | 8.3  |      | 1013.6 |      |      |\n",
    "| 2021-04-16 21:30:15.021410 | atlantes_416.jpg | 18.0 | 9.6   | 58.0  | 0.0  |      | 91.0  | 10.1 |      | 1015.7 |      |      |\n",
    "| 2021-04-16 21:30:30.021508 | atlantes_417.jpg | 17.0 | 11.1  | 68.0  | 0.0  |      | 70.0  | 7.6  |      | 1021.0 |      |      |\n",
    "| 2021-04-16 21:30:45.021579 | atlantes_418.jpg | 18.2 | 12.4  | 69.0  | 0.0  |      | 73.0  | 10.1 |      | 1017.3 |      |      |\n",
    "| 2021-04-16 21:31:00.022159 | atlantes_419.jpg | 14.7 | 11.5  | 81.0  | 0.0  |      | 2.0   | 5.0  |      | 1017.4 |      |      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjEpLALdIFi5"
   },
   "source": [
    "## Sonificación 1: temperatura en ISS y Tierra\n",
    "\n",
    "El objetivo de nuestro proyecto era comparar la estabilidad de las condiciones ambientales a bordo de la estación con las muy rápidamente cambiantes en el mismo instante en la proyección sobre la superficie de la Tierra. Ya tenemos a nuestro alcance los datos. Vamos a representar ambas temperaturas en el sobrevuelo de América. Los datos que nos falten en el fichero de datos de tierra los aproximaremos tomando el valor anterior en la tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "executionInfo": {
     "elapsed": 972,
     "status": "ok",
     "timestamp": 1622565251922,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "3wmlWbUNVXfi",
    "outputId": "6f59edec-688b-4197-d6a0-56098524a9af"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import math\n",
    "\n",
    "file_iss = os.path.join(path_atlantes, RESULTS_FILE)       # Ruta fichero CSV datos ISS\n",
    "file_earth = os.path.join(path_atlantes, RESULTS_FILE4)    # Ruta fichero CSV datos Tierra\n",
    "\n",
    "data_iss = pandas.read_csv(file_iss, nrows=419, parse_dates=[0]).tail(113)        # Leemos sólo las filas que nos interesan\n",
    "data_earth = pandas.read_csv(file_earth, nrows=419, parse_dates=[0]).tail(113)    # Leemos sólo las filas que nos interesan\n",
    "\n",
    "# Columnas en fichero datos ISS: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "# Columnas en fichero datos Tierra: datetime, picture_file, temp, dwpt, rhum, prcp, snow, wdir, wspd, wpgt, pres, tsun, coco\n",
    "data_x = data_iss.datetime                    # Datos de la columna 'datetime'\n",
    "data_y1 = data_iss.temp_p                     # Datos de la columna 'temp_p'\n",
    "data_y2 = data_earth.temp                     # Datos de la columna 'temp'\n",
    "data_y2 = list(data_y2)\n",
    "\n",
    "# Rellenamos los datos que faltan\n",
    "last_y2 = data_y2[0]\n",
    "for i in range(0, len(data_y2)):\n",
    "    if not math.isnan(data_y2[i]):\n",
    "        last_y2 = data_y2[i]\n",
    "    data_y2[i] = last_y2\n",
    "\n",
    "fig, ax = plt.subplots()                      # Preparamos los objetos para dibujar con matplotlib\n",
    "ax.plot(data_x, data_y1, label=\"Temp ISS\")    # Representamos los datos de 'temp_p' frente a 'datetime'\n",
    "ax.plot(data_x, data_y2, label=\"Temp Earth\")  # Representamos los datos de 'temp' frente a 'datetime'\n",
    "\n",
    "plt.legend()                                  # Incluimos una leyenda en la gráfica\n",
    "plt.grid()                                    # Incluimos una rejilla en la gráfica\n",
    "plt.show()                                    # Mostramos la gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOy4ZcM7xr6c"
   },
   "source": [
    "Como era de esperar, la gráfica anterior muestra la ventaja de la estación al volar por encima de la atmósfera, lo que le permite evitar las condiciones tan rápidamente cambiantes a la velocidad a la que se desplaza sobre la superficie terrestre. Seguramente los valores de la temperatura real en la ISS son menores a los obtenidos con el sensor de temperatura de la Raspberry Pi que estará afectada por su propio calor interno. Aunque la variación sí que resulta creíble. De hecho como vimos en el apartado **Gráficas tipo 2: Datos con distintas unidades**, parece encontrarse una correlación de la ligera variación que registra el sensor con el grado de insolación que recibe la estación.\n",
    "\n",
    "Vamos a sonificar las dos series de datos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "output_embedded_package_id": "1tnrDWvkg3sDEbaYg-KJZSlx4bwgTUFuY"
    },
    "executionInfo": {
     "elapsed": 15383,
     "status": "ok",
     "timestamp": 1622565271501,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "GZCrEEoAVc_O",
    "outputId": "63abea55-4ae8-4b7f-8b2d-a213300dde49"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import sonify\n",
    "import IPython\n",
    "\n",
    "file_iss = os.path.join(path_atlantes, RESULTS_FILE)       # Ruta fichero CSV datos ISS\n",
    "file_earth = os.path.join(path_atlantes, RESULTS_FILE4)    # Ruta fichero CSV datos Tierra\n",
    "\n",
    "data_iss = pandas.read_csv(file_iss, nrows=419, parse_dates=[0]).tail(113)        # Leemos sólo las filas que nos interesan\n",
    "data_earth = pandas.read_csv(file_earth, nrows=419, parse_dates=[0]).tail(113)    # Leemos sólo las filas que nos interesan\n",
    "\n",
    "snd_f = \"temperatures_iss_earth\"\n",
    "\n",
    "# Columnas en fichero datos ISS: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "# Columnas en fichero datos Tierra: datetime, picture_file, temp, dwpt, rhum, prcp, snow, wdir, wspd, wpgt, pres, tsun, coco\n",
    "data_x = data_iss.datetime                    # Datos de la columna 'datetime'\n",
    "data_y1 = data_iss.temp_p                     # Datos de la columna 'temp_p'\n",
    "data_y1_normalized = sonify.scale_list_to_range2(data_y1, new_min=20, new_max=100, old_min=0, old_max=35)\n",
    "data_y2 = data_earth.temp                     # Datos de la columna 'temp'\n",
    "data_y2_normalized = sonify.scale_list_to_range2(data_y2, new_min=20, new_max=100, old_min=0, old_max=35)\n",
    "\n",
    "data_x = []\n",
    "x = 0\n",
    "last_y1 = data_y1_normalized[0]\n",
    "last_y2 = data_y2_normalized[0]\n",
    "for i in range(0, len(data_y1_normalized)):\n",
    "    data_x.append(x)\n",
    "    if not math.isnan(data_y1_normalized[i]):\n",
    "        last_y1 = data_y1_normalized[i]\n",
    "    data_y1_normalized[i] = last_y1\n",
    "    if not math.isnan(data_y2_normalized[i]):\n",
    "        last_y2 = data_y2_normalized[i]\n",
    "    data_y2_normalized[i] = last_y2\n",
    "    x += 0.2\n",
    "\n",
    "multitrack_data = []\n",
    "multitrack_data.append(list(zip(data_x, data_y1_normalized)))\n",
    "multitrack_data.append(list(zip(data_x, data_y2_normalized)))\n",
    "\n",
    "# Let's add some instruments to each track!\n",
    "instruments_to_add = ['acoustic grand piano', 'church organ']\n",
    "\n",
    "multitrack_data_with_instruments = []\n",
    "for index, track in enumerate(multitrack_data):\n",
    "    multitrack_data_with_instruments.append([instruments_to_add[index]] + track)\n",
    "\n",
    "sonify.create_midi_from_data(multitrack_data_with_instruments, track_type='multiple', file=snd_f+\".mid\")\n",
    "\n",
    "# Convertimos el fichero MIDI en WAV para reproducirlo en el cuaderno\n",
    "!fluidsynth /content/default.sf2 -F {snd_f}.wav -i -n -T wav {snd_f}.mid\n",
    "IPython.display.Audio(snd_f + \".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTdxq7c0xxZ6"
   },
   "source": [
    "En la sonificación anterior, la temperatura de la ISS es \"interpretada\" por el piano martilleante y la de la superficie en tierra con un órgano. Se observa claramente como la nota del piano es prácticamente constante mientras que el órgano varía el tono continuamente.\n",
    "\n",
    "Esto realmente era nuestro objetivo último, por lo que podríamos considerar terminado nuestro trabajo. Ahora nos gustaría componer un vídeo con las fotos tomadas de la superficie de la Tierra y el sonido que acabamos de crear.\n",
    "\n",
    "Antes de empezar tenemos que preparar las fotos copiando las que hemos seleccionado (desde la `atlantes_307.jpg` hasta la `atlantes_419.jpg`) y renombrándolas para que tengan un número correlativo desde `001` hasta `113`. Ya hemos realizado esa selección sobre el directorio `atlantes_fly_over_america`. Para realizar el vídeo sólo resta ejecutar la siguiente celda. En ella primero se crea un vídeo con la serie de fotos y luego se le añade como banda sonora la sonificación anterior (le cuesta un poco; el reproductor del vídeo en Firefox da un error de MIME types; usar Chrome):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321,
     "output_embedded_package_id": "1R1HNfPs4BpqnIYMgxmetRSo3ubUWPtTF"
    },
    "executionInfo": {
     "elapsed": 30927,
     "status": "ok",
     "timestamp": 1622565308909,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "VWIl7RLcYeZV",
    "outputId": "9ef2c98d-1d68-4d99-cc24-14851a5b7328"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "!ffmpeg -y -loglevel quiet -f image2 -r 5 -i atlantes_fly_over_america/%03d.jpg -vf scale=320:240 -r:v 5 -c:v libx264 -qp 0 -preset veryslow -an fly_over_america_video.mp4\n",
    "!ffmpeg -y -loglevel quiet -i fly_over_america_video.mp4 -i temperatures_iss_earth.wav -c:v copy -c:a aac temperatures_iss_earth.mp4\n",
    "\n",
    "mp4 = open('temperatures_iss_earth.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVv1jmfex5eY"
   },
   "source": [
    "El mismo vídeo en alta resolución en YouTube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1622565312635,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "i-4mgT_fe_y4",
    "outputId": "7546f083-b0cd-4886-b240-f791e2eced3f"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.YouTubeVideo('Hl1exe3S_cI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9AEPUnayXNB"
   },
   "source": [
    "Observando el resultado final, parece detectarse cómo la temperatura al sobrevolar el mar es en general más alta (se detecta por las notas más agudas del órgano). También se detecta que en general la temperatura en sudamérica es más alta que en norteamérica.\n",
    "\n",
    "En teoría ya habríamos conseguido el objetivo de nuestro proyecto. A partir de ahora, vamos a aprovechar que ya dominamos las técnicas para sonificar series de datos y para crear vídeos stopmotion con las fotos, para tratar de conseguir sonificaciones más efectistas.\n",
    "\n",
    "Vamos a intentar más sonificaciones con los datos que tenemos para ver si tenemos suerte y alguna de ellas resulta medianamente armónica.\n",
    "\n",
    "El resultado de sonificar varias de las columnas de datos del sobrevuelo por el continente americano (concretamente temp, dwpt, rhum, wspd y pres) resultó demasiado cacofónico como se puede comprobar a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61,
     "output_embedded_package_id": "1lW4z3taozuUPxQbFyTkTtyKPS84oKV-B"
    },
    "executionInfo": {
     "elapsed": 14673,
     "status": "ok",
     "timestamp": 1622565330463,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "GVtUGXQOfFXx",
    "outputId": "503ef749-fb53-434e-8a9d-3cd8d79c3eac"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.Audio(\"temp_dwpt_rhum_wspd_pres.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UY_ueeI00XXW"
   },
   "source": [
    "Por lo que decidimos continuar con la estrategia de sonificar los datos por separado como hicimos con la temperatura.\n",
    "\n",
    "Los únicos datos comparables entre ISS y Tierra además de la temperatura que ya hemos utilizado, son:\n",
    "\n",
    "* humidity\n",
    "* pressure\n",
    "\n",
    "Vamos pues a repetir el proceso hecho la temperatura pero esta vez con humedad y presión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PthaMEEILi9"
   },
   "source": [
    "## Sonificación 2: humedad relativa en ISS y Tierra\n",
    "\n",
    "Empezamos haciendo una representación gráfica de lo que vamos a sonificar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1622565334146,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "z0-6zuZgkqPn",
    "outputId": "9542e867-bfdd-4790-ccb1-1453aefd9322"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import math\n",
    "\n",
    "file_iss = os.path.join(path_atlantes, RESULTS_FILE)       # Ruta fichero CSV datos ISS\n",
    "file_earth = os.path.join(path_atlantes, RESULTS_FILE4)    # Ruta fichero CSV datos Tierra\n",
    "\n",
    "data_iss = pandas.read_csv(file_iss, nrows=419, parse_dates=[0]).tail(113)        # Leemos sólo las filas que nos interesan\n",
    "data_earth = pandas.read_csv(file_earth, nrows=419, parse_dates=[0]).tail(113)    # Leemos sólo las filas que nos interesan\n",
    "\n",
    "# Columnas en fichero datos ISS: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "# Columnas en fichero datos Tierra: datetime, picture_file, temp, dwpt, rhum, prcp, snow, wdir, wspd, wpgt, pres, tsun, coco\n",
    "data_x = data_iss.datetime                    # Datos de la columna 'datetime'\n",
    "data_y1 = data_iss.humidity                   # Datos de la columna 'humidity'\n",
    "data_y2 = data_earth.rhum                     # Datos de la columna 'rhum'\n",
    "data_y2 = list(data_y2)\n",
    "\n",
    "# Rellenamos los datos que faltan\n",
    "last_y2 = data_y2[0]\n",
    "for i in range(0, len(data_y2)):\n",
    "    if not math.isnan(data_y2[i]):\n",
    "        last_y2 = data_y2[i]\n",
    "    data_y2[i] = last_y2\n",
    "\n",
    "fig, ax = plt.subplots()                      # Preparamos los objetos para dibujar con matplotlib\n",
    "ax.plot(data_x, data_y1, label=\"Humedad relativa ISS\")    # Representamos los datos de 'humidity' frente a 'datetime'\n",
    "ax.plot(data_x, data_y2, label=\"Humedad relativa Earth\")  # Representamos los datos de 'rhum' frente a 'datetime'\n",
    "\n",
    "plt.legend()                                  # Incluimos una leyenda en la gráfica\n",
    "plt.grid()                                    # Incluimos una rejilla en la gráfica\n",
    "plt.show()                                    # Mostramos la gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnvaEg7T0cCP"
   },
   "source": [
    "Finalmente sonificamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "output_embedded_package_id": "10r0_x5JYaKOIRDkFzTuK285ZAmcS4728"
    },
    "executionInfo": {
     "elapsed": 14843,
     "status": "ok",
     "timestamp": 1622565353776,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "_A6qZKYokwT4",
    "outputId": "74a90dcf-597b-44e1-809f-e3e84a5c60fd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import sonify\n",
    "import IPython\n",
    "\n",
    "file_iss = os.path.join(path_atlantes, RESULTS_FILE)       # Ruta fichero CSV datos ISS\n",
    "file_earth = os.path.join(path_atlantes, RESULTS_FILE4)    # Ruta fichero CSV datos Tierra\n",
    "\n",
    "data_iss = pandas.read_csv(file_iss, nrows=419, parse_dates=[0]).tail(113)        # Leemos sólo las filas que nos interesan\n",
    "data_earth = pandas.read_csv(file_earth, nrows=419, parse_dates=[0]).tail(113)    # Leemos sólo las filas que nos interesan\n",
    "\n",
    "snd_f = \"humidity_iss_earth\"\n",
    "\n",
    "# Columnas en fichero datos ISS: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "# Columnas en fichero datos Tierra: datetime, picture_file, temp, dwpt, rhum, prcp, snow, wdir, wspd, wpgt, pres, tsun, coco\n",
    "data_x = data_iss.datetime                    # Datos de la columna 'datetime'\n",
    "data_y1 = data_iss.humidity                     # Datos de la columna 'humidity'\n",
    "data_y1_normalized = sonify.scale_list_to_range2(data_y1, new_min=20, new_max=100, old_min=0, old_max=100)\n",
    "data_y2 = data_earth.rhum                     # Datos de la columna 'rhum'\n",
    "data_y2_normalized = sonify.scale_list_to_range2(data_y2, new_min=20, new_max=100, old_min=0, old_max=100)\n",
    "\n",
    "data_x = []\n",
    "x = 0\n",
    "last_y1 = data_y1_normalized[0]\n",
    "last_y2 = data_y2_normalized[0]\n",
    "for i in range(0, len(data_y1_normalized)):\n",
    "    data_x.append(x)\n",
    "    if not math.isnan(data_y1_normalized[i]):\n",
    "        last_y1 = data_y1_normalized[i]\n",
    "    data_y1_normalized[i] = last_y1\n",
    "    if not math.isnan(data_y2_normalized[i]):\n",
    "        last_y2 = data_y2_normalized[i]\n",
    "    data_y2_normalized[i] = last_y2\n",
    "    x += 0.2\n",
    "\n",
    "multitrack_data = []\n",
    "multitrack_data.append(list(zip(data_x, data_y1_normalized)))\n",
    "multitrack_data.append(list(zip(data_x, data_y2_normalized)))\n",
    "\n",
    "# Let's add some instruments to each track!\n",
    "instruments_to_add = ['acoustic grand piano', 'church organ']\n",
    "\n",
    "multitrack_data_with_instruments = []\n",
    "for index, track in enumerate(multitrack_data):\n",
    "    multitrack_data_with_instruments.append([instruments_to_add[index]] + track)\n",
    "\n",
    "sonify.create_midi_from_data(multitrack_data_with_instruments, track_type='multiple', file=snd_f+\".mid\")\n",
    "\n",
    "# Convertimos el fichero MIDI en WAV para reproducirlo en el cuaderno\n",
    "!fluidsynth /content/default.sf2 -F {snd_f}.wav -i -n -T wav {snd_f}.mid\n",
    "IPython.display.Audio(snd_f + \".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XHyElYg0f_7"
   },
   "source": [
    "El resultado sigue sin ser muy espectacular y similar a lo obtenido con las temperaturas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ogk4sHPLIepF"
   },
   "source": [
    "## Sonificación 3: presión en ISS y Tierra\n",
    "\n",
    "Empezamos haciendo una representación gráfica de lo que vamos a sonificar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1622565358438,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "0e3XH6ZCk_4Z",
    "outputId": "224427c9-7194-46e3-d80d-4ff5b8a1985a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import math\n",
    "\n",
    "file_iss = os.path.join(path_atlantes, RESULTS_FILE)       # Ruta fichero CSV datos ISS\n",
    "file_earth = os.path.join(path_atlantes, RESULTS_FILE4)    # Ruta fichero CSV datos Tierra\n",
    "\n",
    "data_iss = pandas.read_csv(file_iss, nrows=419, parse_dates=[0]).tail(113)        # Leemos sólo las filas que nos interesan\n",
    "data_earth = pandas.read_csv(file_earth, nrows=419, parse_dates=[0]).tail(113)    # Leemos sólo las filas que nos interesan\n",
    "\n",
    "# Columnas en fichero datos ISS: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "# Columnas en fichero datos Tierra: datetime, picture_file, temp, dwpt, rhum, prcp, snow, wdir, wspd, wpgt, pres, tsun, coco\n",
    "data_x = data_iss.datetime                    # Datos de la columna 'datetime'\n",
    "data_y1 = data_iss.pressure                   # Datos de la columna 'pressure'\n",
    "data_y2 = data_earth.pres                     # Datos de la columna 'pres'\n",
    "data_y2 = list(data_y2)\n",
    "\n",
    "# Rellenamos los datos que faltan\n",
    "last_y2 = data_y2[0]\n",
    "for i in range(0, len(data_y2)):\n",
    "    if not math.isnan(data_y2[i]):\n",
    "        last_y2 = data_y2[i]\n",
    "    data_y2[i] = last_y2\n",
    "\n",
    "fig, ax = plt.subplots()                      # Preparamos los objetos para dibujar con matplotlib\n",
    "ax.plot(data_x, data_y1, label=\"Presión ISS\")    # Representamos los datos de 'pressure' frente a 'datetime'\n",
    "ax.plot(data_x, data_y2, label=\"Presión Earth\")  # Representamos los datos de 'pres' frente a 'datetime'\n",
    "\n",
    "plt.legend()                                  # Incluimos una leyenda en la gráfica\n",
    "plt.grid()                                    # Incluimos una rejilla en la gráfica\n",
    "plt.show()                                    # Mostramos la gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7o-eGO910k-A"
   },
   "source": [
    "Sonificando..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "output_embedded_package_id": "1WBfx8trA2ps7wExsguc1LscQwKw5a--h"
    },
    "executionInfo": {
     "elapsed": 15165,
     "status": "ok",
     "timestamp": 1622565377337,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "oS_6jCnQlDYx",
    "outputId": "e83f5bf4-e196-4f4a-8521-816143cdc49b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import sonify\n",
    "import IPython\n",
    "\n",
    "file_iss = os.path.join(path_atlantes, RESULTS_FILE)       # Ruta fichero CSV datos ISS\n",
    "file_earth = os.path.join(path_atlantes, RESULTS_FILE4)    # Ruta fichero CSV datos Tierra\n",
    "\n",
    "data_iss = pandas.read_csv(file_iss, nrows=419, parse_dates=[0]).tail(113)        # Leemos sólo las filas que nos interesan\n",
    "data_earth = pandas.read_csv(file_earth, nrows=419, parse_dates=[0]).tail(113)    # Leemos sólo las filas que nos interesan\n",
    "\n",
    "snd_f = \"pressure_iss_earth\"\n",
    "\n",
    "# Columnas en fichero datos ISS: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "# Columnas en fichero datos Tierra: datetime, picture_file, temp, dwpt, rhum, prcp, snow, wdir, wspd, wpgt, pres, tsun, coco\n",
    "data_x = data_iss.datetime                    # Datos de la columna 'datetime'\n",
    "data_y1 = data_iss.pressure                     # Datos de la columna 'pressure'\n",
    "data_y1_normalized = sonify.scale_list_to_range2(data_y1, new_min=20, new_max=100, old_min=980, old_max=1030)\n",
    "data_y2 = data_earth.pres                     # Datos de la columna 'pres'\n",
    "data_y2_normalized = sonify.scale_list_to_range2(data_y2, new_min=20, new_max=100, old_min=980, old_max=1030)\n",
    "\n",
    "data_x = []\n",
    "x = 0\n",
    "last_y1 = data_y1_normalized[0]\n",
    "last_y2 = data_y2_normalized[0]\n",
    "for i in range(0, len(data_y1_normalized)):\n",
    "    data_x.append(x)\n",
    "    if not math.isnan(data_y1_normalized[i]):\n",
    "        last_y1 = data_y1_normalized[i]\n",
    "    data_y1_normalized[i] = last_y1\n",
    "    if not math.isnan(data_y2_normalized[i]):\n",
    "        last_y2 = data_y2_normalized[i]\n",
    "    data_y2_normalized[i] = last_y2\n",
    "    x += 0.2\n",
    "\n",
    "multitrack_data = []\n",
    "multitrack_data.append(list(zip(data_x, data_y1_normalized)))\n",
    "multitrack_data.append(list(zip(data_x, data_y2_normalized)))\n",
    "\n",
    "# Let's add some instruments to each track!\n",
    "instruments_to_add = ['acoustic grand piano', 'church organ']\n",
    "\n",
    "multitrack_data_with_instruments = []\n",
    "for index, track in enumerate(multitrack_data):\n",
    "    multitrack_data_with_instruments.append([instruments_to_add[index]] + track)\n",
    "\n",
    "sonify.create_midi_from_data(multitrack_data_with_instruments, track_type='multiple', file=snd_f+\".mid\")\n",
    "\n",
    "# Convertimos el fichero MIDI en WAV para reproducirlo en el cuaderno\n",
    "!fluidsynth /content/default.sf2 -F {snd_f}.wav -i -n -T wav {snd_f}.mid\n",
    "IPython.display.Audio(snd_f + \".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ks29hbGqImBO"
   },
   "source": [
    "De nuevo, nada rompedor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YGPwuAK0pOz"
   },
   "source": [
    "## Sonificación 4: componentes magnetómetro en ISS\n",
    "\n",
    "Vamos a cambiar de estrategia. Representando gráficamente todos los datos capturados en la estación por el programa ejecutado en AstroPi, se encuentra que las únicas magnitudes que producen un espectro de valores continuo y cuya variación puede tener algún interés son:\n",
    "\n",
    "* yaw\n",
    "* mag_x\n",
    "* mag_y\n",
    "* mag_z\n",
    "\n",
    "Como las únicas que tiene sentido manejar en conjunto son las tres últimas, vamos a centrarnos en ellas. Empezamos representando gráficamente su variación. Esta vez vamos a utilizar el conjunto de datos, no sólo el sobrevuelo sobre América."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "executionInfo": {
     "elapsed": 765,
     "status": "ok",
     "timestamp": 1622565382451,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "Bj5zoiZjlQTd",
    "outputId": "a6c27fa5-09ff-49c4-b5c1-6b037fa70d67"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import math\n",
    "\n",
    "file_iss = os.path.join(path_atlantes, RESULTS_FILE)       # Ruta fichero CSV datos ISS\n",
    "data_iss = pandas.read_csv(file_iss, parse_dates=[0])       # Leemos todo el fichero\n",
    "\n",
    "# Columnas en fichero datos ISS: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "data_x = data_iss.datetime\n",
    "data_y1 = data_iss.mag_x\n",
    "data_y2 = data_iss.mag_y\n",
    "data_y3 = data_iss.mag_z\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data_x, data_y1, label=\"mag_x\")\n",
    "ax.plot(data_x, data_y2, label=\"mag_y\")\n",
    "ax.plot(data_x, data_y3, label=\"mag_z\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwRTJlmf0uwf"
   },
   "source": [
    "La sonificación es la siguiente. Esta vez hemos acelerado el ritmo (una nota cada décima de segundo) ya que vamos a utilizar todos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "output_embedded_package_id": "19odFbEDFhKRG-PSov8REXHxK4ZKLKh6j"
    },
    "executionInfo": {
     "elapsed": 47389,
     "status": "ok",
     "timestamp": 1622565433387,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "jWkL1JFclT5L",
    "outputId": "a23aa990-a13f-4f8b-f9e3-1ef22f41496a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import sonify\n",
    "import IPython\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE)    # Ruta completa fichero CSV\n",
    "snd_f = \"mag_xyz\"\n",
    "\n",
    "data = pandas.read_csv(file, parse_dates=[0])       # Leemos todo el fichero\n",
    "\n",
    "# Columnas en fichero: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "data_x = data.datetime                              # Datos de la columna 'datetime'\n",
    "data_y1 = data.mag_x                                # Datos de la columna 'mag_x'\n",
    "data_y1_normalized = sonify.scale_list_to_range2(data_y1, new_min=20, new_max=100, old_min=-20, old_max=70)\n",
    "data_y2 = data.mag_y                                # Datos de la columna 'mag_y'\n",
    "data_y2_normalized = sonify.scale_list_to_range2(data_y2, new_min=20, new_max=100, old_min=-20, old_max=70)\n",
    "data_y3 = data.mag_z                                # Datos de la columna 'mag_z'\n",
    "data_y3_normalized = sonify.scale_list_to_range2(data_y3, new_min=20, new_max=100, old_min=-20, old_max=70)\n",
    "\n",
    "data_x = []\n",
    "x = 0\n",
    "for i in range(0, len(data_y1_normalized)):\n",
    "    data_x.append(x)\n",
    "    x += 0.1\n",
    "\n",
    "\n",
    "multitrack_data = []\n",
    "multitrack_data.append(list(zip(data_x, data_y1_normalized)))\n",
    "multitrack_data.append(list(zip(data_x, data_y2_normalized)))\n",
    "multitrack_data.append(list(zip(data_x, data_y3_normalized)))\n",
    "\n",
    "\n",
    "# Let's add some instruments to each track!\n",
    "instruments_to_add = ['church organ', 'accordion', 'cello']\n",
    "\n",
    "multitrack_data_with_instruments = []\n",
    "for index, track in enumerate(multitrack_data):\n",
    "    multitrack_data_with_instruments.append([instruments_to_add[index]] + track)\n",
    "\n",
    "\n",
    "sonify.create_midi_from_data(multitrack_data_with_instruments, track_type='multiple', file=snd_f+\".mid\")\n",
    "\n",
    "# Convertimos el fichero MIDI en WAV para reproducirlo en el cuaderno\n",
    "!fluidsynth /content/default.sf2 -F {snd_f}.wav -i -n -T wav {snd_f}.mid\n",
    "IPython.display.Audio(snd_f+\".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kU5Y5gGH0yi5"
   },
   "source": [
    "Creamos el vídeo stopmotion con esta sonificación (la ejecución de la siguiente celda tarda un poco):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321,
     "output_embedded_package_id": "15vw8dvHlwIlFm_vEBKrMfKg9l2PolUxy"
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1622565630368,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "WTccD_lvlhh3",
    "outputId": "295b0d67-5258-4fe7-af71-2cf1e3e166b1"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "!ffmpeg -y -loglevel quiet -f image2 -r 10 -i atlantes/atlantes_%03d.jpg -vf scale=320:240 -r:v 10 -c:v libx264 -qp 0 -preset veryslow -an complete_fly_video.mp4\n",
    "!ffmpeg -y -loglevel quiet -i complete_fly_video.mp4 -i mag_xyz.wav -c:v copy -c:a aac mag_xyz.mp4\n",
    "\n",
    "mp4 = open('mag_xyz.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXJgh3oy03wB"
   },
   "source": [
    "El mismo vídeo en alta resolución en YouTube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1622565637480,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "8bwVzWc0mrAL",
    "outputId": "ffd660d1-6cee-4d9c-ea7e-785807ddef84"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.YouTubeVideo('VSILkRGMKdA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyOiQL6MbPP"
   },
   "source": [
    "## Sonificación 5: módulo magnetómetro en ISS\n",
    "\n",
    "Vamos a calcular el módulo del vector compuesto por las magnitudes `mag_x`, `mag_y` y `mag_z`, para ver cómo varía la intensidad del campo magnético de la Tierra durante la órbita de la ISS. El módulo se calcula con la siguiente función:\n",
    "\n",
    "$Mag = \\sqrt{mag_x^2 + mag_y^2 + mag_z^2}$\n",
    "\n",
    "Empezamos representando dicho módulo gráficamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1622565641995,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "zCYldMMvMkx6",
    "outputId": "32bc38f2-e009-420f-9534-b8db82e25843"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy\n",
    "import sonify\n",
    "import IPython\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE)    # Ruta completa fichero CSV\n",
    "snd_f = \"mag_xyz\"\n",
    "\n",
    "data = pandas.read_csv(file, parse_dates=[0])       # Leemos todo el fichero\n",
    "\n",
    "# Columnas en fichero: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "data_x = data.datetime                              # Datos de la columna 'datetime'\n",
    "data_y1 = data.mag_x                                # Datos de la columna 'mag_x'\n",
    "data_y2 = data.mag_y                                # Datos de la columna 'mag_y'\n",
    "data_y3 = data.mag_z                                # Datos de la columna 'mag_z'\n",
    "\n",
    "data_y = numpy.sqrt(data_y1.pow(2) + data_y2.pow(2) + data_y3.pow(2))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data_x, data_y, label=\"Mag\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gD75It-MpMM"
   },
   "source": [
    "La sonificación de lo anterior será:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "output_embedded_package_id": "1tCnfxKNKHrX6JvPr9_zHdhyhGrKq6OO5"
    },
    "executionInfo": {
     "elapsed": 44379,
     "status": "ok",
     "timestamp": 1622565689478,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "ewsS1dRjMqDc",
    "outputId": "d12f7408-bd6d-4925-a856-e58b2fa3937d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy\n",
    "import sonify\n",
    "import IPython\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE)    # Ruta completa fichero CSV\n",
    "snd_f = \"mag\"\n",
    "\n",
    "data = pandas.read_csv(file, parse_dates=[0])       # Leemos sólo los datos que nos interesan\n",
    "\n",
    "# Columnas en fichero: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "data_x = data.datetime                              # Datos de la columna 'datetime'\n",
    "data_y1 = data.mag_x                                # Datos de la columna 'mag_x'\n",
    "data_y2 = data.mag_y                                # Datos de la columna 'mag_y'\n",
    "data_y3 = data.mag_z                                # Datos de la columna 'mag_z'\n",
    "\n",
    "data_y = numpy.sqrt(data_y1.pow(2) + data_y2.pow(2) + data_y3.pow(2))\n",
    "\n",
    "# Normalizamos los datos entre 20 y 100\n",
    "lista_normalizada = sonify.scale_list_to_range(data_y, new_min=20, new_max=100)\n",
    "\n",
    "data_x = []\n",
    "x = 0\n",
    "for i in range(0, len(lista_normalizada)):\n",
    "    data_x.append(x)\n",
    "    x += 0.1\n",
    "\n",
    "list_of_lists = []\n",
    "list_of_lists.append(['church organ'] + list(zip(data_x, lista_normalizada)))\n",
    "\n",
    "sonify.create_midi_from_data(list_of_lists, track_type='multiple', key='c_major', file=snd_f+\".mid\")\n",
    "\n",
    "# Convertimos el fichero MIDI en WAV para reproducirlo en el cuaderno\n",
    "!fluidsynth /content/default.sf2 -F {snd_f}.wav -i -n -T wav {snd_f}.mid\n",
    "IPython.display.Audio(snd_f+\".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qqc1ljwFNSuV"
   },
   "source": [
    "Como siempre, insertamos la sonificación al vídeo correspondiente (en este caso a la secuencia completa de fotos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321,
     "output_embedded_package_id": "1xqDVgXB62j3nwO04HpxSJmqLVWvNt2j9"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1622565860520,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "tdGfSZTXNU0x",
    "outputId": "29047941-e700-414c-9e1c-6447ae9dc418"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "!ffmpeg -y -loglevel quiet -i complete_fly_video.mp4 -i mag.wav -c:v copy -c:a aac mag.mp4\n",
    "\n",
    "mp4 = open('mag.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xwKxO2rNo-4"
   },
   "source": [
    "El mismo vídeo en alta resolución en YouTube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1622565863188,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "j6dKjb77Npo5",
    "outputId": "05befd8e-7948-4e42-ebe3-e44ce0931751"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.YouTubeVideo('nXT9t3kGm1o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy-JZVOv09u-"
   },
   "source": [
    "## Sonificación 6: imágenes\n",
    "\n",
    "En el apartado **Sonificando las medias de las fotografías** sonificamos las medias de los valores de los píxeles de las imágenes. Vamos a trabajar un poco más sobre esto ya que es la información cuya sonificación sincronizará mejor con la animación de dichas imágenes.\n",
    "\n",
    "Para no hacer el vídeo muy largo y para que tenga un principio y final gradual, vamos a trabajar únicamente con los datos que van desde la imagen `atlantes_186.jpg` hasta `atlantes_431.jpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE3)    # Ruta completa fichero CSV\n",
    "\n",
    "# Leemos sólo los datos que nos interesan\n",
    "data = pandas.read_csv(file, nrows=431, parse_dates=[0]).tail(246)\n",
    "\n",
    "# Columnas en fichero: \"datetime\", \"picture_file\", \"mean_global\", \"mean_r\", \"mean_g\", \"mean_b\"\n",
    "data_x = data.datetime                        # Datos de la columna 'datetime'\n",
    "data_y1 = data.mean_global                    # Datos de la columna 'mean_global'\n",
    "data_y2 = data.mean_r                         # Datos de la columna 'mean_r'\n",
    "data_y3 = data.mean_g                         # Datos de la columna 'mean_g'\n",
    "data_y4 = data.mean_b                         # Datos de la columna 'mean_b'\n",
    "\n",
    "fig, ax = plt.subplots()                                      # Preparamos los objetos para dibujar con matplotlib\n",
    "ax.plot(data_x, data_y1, label=\"Mean global\", color=\"yellow\") # Representamos los datos de 'mean_global' frente a 'datetime'\n",
    "ax.plot(data_x, data_y2, label=\"Mean R\", color=\"red\")         # Representamos los datos de 'mean_r' frente a 'datetime'\n",
    "ax.plot(data_x, data_y3, label=\"Mean G\", color=\"green\")       # Representamos los datos de 'mean_g' frente a 'datetime'\n",
    "ax.plot(data_x, data_y4, label=\"Mean B\", color=\"blue\")        # Representamos los datos de 'mean_b' frente a 'datetime'\n",
    "\n",
    "plt.legend()                                  # Incluimos una leyenda en la gráfica\n",
    "plt.grid()                                    # Incluimos una rejilla en la gráfica\n",
    "plt.show()                                    # Mostramos la gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos sonificando las medias de los cuatro canales de datos que tenemos asociados a las imágenes para el rango de fotos que acabamos de comentar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "output_embedded_package_id": "1P90CrKa3nK4AowbbrHOsP1kBsDI6w-8V"
    },
    "executionInfo": {
     "elapsed": 16905,
     "status": "ok",
     "timestamp": 1622565883789,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "qosy5QsgniDn",
    "outputId": "1e0364ab-8540-4d6c-c47f-96b50859ba7f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import sonify\n",
    "import IPython\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE3)    # Ruta completa fichero CSV\n",
    "snd_f = \"1orbit_pictures_means\"\n",
    "\n",
    "data = pandas.read_csv(file, nrows=431, parse_dates=[0]).tail(246)        # Leemos sólo las filas que nos interesan\n",
    "\n",
    "# Columnas en fichero: \"datetime\", \"picture_file\", \"mean_global\", \"mean_r\", \"mean_g\", \"mean_b\"\n",
    "data_y1 = data.mean_global                    # Datos de la columna 'mean_global'\n",
    "data_y1_normalized = sonify.scale_list_to_range(data_y1, new_min=20, new_max=100)\n",
    "data_y2 = data.mean_r                         # Datos de la columna 'mean_r'\n",
    "data_y2_normalized = sonify.scale_list_to_range(data_y2, new_min=20, new_max=100)\n",
    "data_y3 = data.mean_g                         # Datos de la columna 'mean_g'\n",
    "data_y3_normalized = sonify.scale_list_to_range(data_y3, new_min=20, new_max=100)\n",
    "data_y4 = data.mean_b                         # Datos de la columna 'mean_b'\n",
    "data_y4_normalized = sonify.scale_list_to_range(data_y4, new_min=20, new_max=100)\n",
    "\n",
    "data_x = []\n",
    "x = 0\n",
    "for i in range(0, len(data_y1_normalized)):\n",
    "    data_x.append(x)\n",
    "    x += 0.1\n",
    "\n",
    "multitrack_data = []\n",
    "multitrack_data.append(list(zip(data_x, data_y1_normalized)))\n",
    "multitrack_data.append(list(zip(data_x, data_y2_normalized)))\n",
    "multitrack_data.append(list(zip(data_x, data_y3_normalized)))\n",
    "multitrack_data.append(list(zip(data_x, data_y4_normalized)))\n",
    "\n",
    "# Let's add some instruments to each track!\n",
    "instruments_to_add = ['steel drums', 'rock organ', 'pizzicato strings', 'oboe']\n",
    "\n",
    "multitrack_data_with_instruments = []\n",
    "for index, track in enumerate(multitrack_data):\n",
    "    multitrack_data_with_instruments.append([instruments_to_add[index]] + track)\n",
    "\n",
    "sonify.create_midi_from_data(multitrack_data_with_instruments, track_type='multiple', key='c_major', file=snd_f+\".mid\")\n",
    "\n",
    "# Convertimos el fichero MIDI en WAV para reproducirlo en el cuaderno\n",
    "!fluidsynth /content/default.sf2 -F {snd_f}.wav -i -n -T wav {snd_f}.mid\n",
    "IPython.display.Audio(snd_f+\".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idHtR8Nq1B_E"
   },
   "source": [
    "Ahora construimos el vídeo con esas imágenes y le acoplamos la sonificación anterior. Al igual que hicimos en la **Sonificación 1**, antes de empezar tenemos que preparar las fotos copiando las que hemos seleccionado (desde la `atlantes_186.jpg` hasta la `atlantes_431.jpg`) y renombrándolas para que tengan un número correlativo desde 001 hasta 246. Hemos realizado esa selección sobre el directorio `atlantes_1orbit`. Para realizar el vídeo sólo resta ejecutar la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321,
     "output_embedded_package_id": "1GZ5UM3k7-3u3wy3oz7CV7rQiY7usq2PP"
    },
    "executionInfo": {
     "elapsed": 51688,
     "status": "ok",
     "timestamp": 1622565943097,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "7xUMV1E0nsyn",
    "outputId": "b84b14b3-eaf5-4162-ac06-52dfd5a4b0a8"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "!ffmpeg -y -loglevel quiet -f image2 -r 10 -i atlantes_1orbit/%03d.jpg -vf scale=320:240 -r:v 10 -c:v libx264 -qp 0 -preset veryslow -an 1orbit_video.mp4\n",
    "!ffmpeg -y -loglevel quiet -i 1orbit_video.mp4 -i 1orbit_pictures_means.wav -c:v copy -c:a aac 1orbit_pictures_means.mp4\n",
    "\n",
    "mp4 = open('1orbit_pictures_means.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Kh_p7tF1Fwz"
   },
   "source": [
    "El mismo vídeo en alta resolución en YouTube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1622565948480,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "owf_gNscoYsv",
    "outputId": "771d8e8e-b184-4613-e290-5ce9a4783844"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.YouTubeVideo('SL1XojuapDE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2iZdtDV1BgE"
   },
   "source": [
    "## Sonificación 7: latitud\n",
    "\n",
    "Otra sonificación que seguramente resulta interesante es la de la latitud de la estación. Esta magnitud tiene forma senoidal, lo que debería producir una variación de sonido continua y gradual. Aunque a la hora de ver el vídeo no se aprecia la relación entre las notas y las imágenes, la sonificación ayuda a interpretar lo que estamos viendo al permitir la identificación inmediata a de la latitud de las fotografías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1622565952473,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "2yRomPvmAhNq",
    "outputId": "e30f129f-e2d9-44b2-b673-09f97b73ed54"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy\n",
    "import sonify\n",
    "import IPython\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE)    # Ruta completa fichero CSV\n",
    "snd_f = \"latitude\"\n",
    "\n",
    "data = pandas.read_csv(file, parse_dates=[0])       # Leemos todo el fichero\n",
    "\n",
    "# Columnas en fichero: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "data_x = data.datetime                              # Datos de la columna 'datetime'\n",
    "data_y = data.latitude                              # Datos de la columna 'latitude'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data_x, data_y, label=\"Latitude\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "output_embedded_package_id": "1e0QybdkaKIs9XgI62gXd4qeFpdwi8R_G"
    },
    "executionInfo": {
     "elapsed": 45017,
     "status": "ok",
     "timestamp": 1622566013350,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "JioYgouR1-cw",
    "outputId": "0725b8e4-2f73-4550-b12b-fb0b4d58de4f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import sonify\n",
    "import IPython\n",
    "\n",
    "file = os.path.join(path_atlantes, RESULTS_FILE)     # Ruta completa fichero CSV\n",
    "snd_f = \"latitude\"\n",
    "\n",
    "data = pandas.read_csv(file, parse_dates=[0])        # Leemos todo el fichero\n",
    "\n",
    "# Columnas en fichero: datetime,picture_file,latitude,longitude,temp_cpu,temp_h,temp_p,humidity,pressure,pitch,roll,yaw,mag_x,mag_y,mag_z,accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z\n",
    "data_y1 = data.latitude                              # Datos de la columna 'latitude'\n",
    "data_y1_normalized = sonify.scale_list_to_range(data_y1, new_min=20, new_max=100)\n",
    "\n",
    "final_data = []\n",
    "x = 0\n",
    "for i in range(0, len(data_y1_normalized)):\n",
    "    final_data.append((x, data_y1_normalized[i]))\n",
    "    x += 0.1\n",
    "\n",
    "sonify.create_midi_from_data(final_data, file=snd_f+\".mid\")\n",
    "\n",
    "# Convertimos el fichero MIDI en WAV para reproducirlo en el cuaderno\n",
    "!fluidsynth /content/default.sf2 -F {snd_f}.wav -i -n -T wav {snd_f}.mid\n",
    "IPython.display.Audio(snd_f+\".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPf-5jqEBCcG"
   },
   "source": [
    "Creamos el vídeo stopmotion con esta sonificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321,
     "output_embedded_package_id": "1gnnla3gNoBe5z9AB7pnVa706oVwDGcti"
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1622566185984,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "kpkuRQ3dBIz2",
    "outputId": "15735ef5-cfad-4be1-dffa-83a3119ff64f"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "#!ffmpeg -y -loglevel quiet -f image2 -r 10 -i atlantes/atlantes_%03d.jpg -vf scale=320:240 -r:v 10 -c:v libx264 -qp 0 -preset veryslow -an complete_fly_video.mp4\n",
    "!ffmpeg -y -loglevel quiet -i complete_fly_video.mp4 -i latitude.wav -c:v copy -c:a aac latitude.mp4\n",
    "\n",
    "mp4 = open('latitude.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNGFvpQ5FQ6D"
   },
   "source": [
    "El mismo vídeo en alta resolución en YouTube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "executionInfo": {
     "elapsed": 503,
     "status": "ok",
     "timestamp": 1622566189187,
     "user": {
      "displayName": "Eduardo niubit",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj0y9aRubnGqyBwnTX2iunDV_1aq6HLGb3OAcka=s64",
      "userId": "01074621491451213101"
     },
     "user_tz": -120
    },
    "id": "w5M-yghBDUD3",
    "outputId": "5362d618-60d2-4bbf-ced7-eacab666d1fc"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.YouTubeVideo('G8YluWG5hmw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9nw6JTg1JRv"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**FIN**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMvlUtJSrcPy2obVc+4BEK2",
   "collapsed_sections": [],
   "name": "P4 Atlantes AstroPi (es).ipynb",
   "provenance": [
    {
     "file_id": "1MbKih4KNsLCapT-hjhKCPS7X5l224bSM",
     "timestamp": 1622109630514
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
